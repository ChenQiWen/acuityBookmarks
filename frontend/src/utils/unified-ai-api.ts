/**
 * ç»Ÿä¸€ AI Service
 * - å°è£…å¯¹ Cloudflare Worker /api/ai/complete çš„è°ƒç”¨
 * - æä¾› completionï¼ˆå•è½®ï¼‰ä¸ chatï¼ˆå¤šè½®ï¼‰ä¸¤ç§æ¥å£
 * - å¥å£®çš„é”™è¯¯å¤„ç†ä¸è¶…æ—¶æ§åˆ¶
 */

export type AiRole = 'system' | 'user' | 'assistant';

export interface AiMessage {
  role: AiRole;
  content: string;
}

export interface AiCompleteOptions {
  model?: string; // é»˜è®¤: '@cf/meta/llama-3.1-8b-instruct'
  temperature?: number; // é»˜è®¤: 0.6
  maxTokens?: number; // é»˜è®¤: 256
  stream?: boolean; // ç›®å‰å‰ç«¯ä¸å¤„ç†SSEæµ, å»ºè®® false
  signal?: AbortSignal;
}

export interface AiChatOptions extends AiCompleteOptions {}

export interface AiResponseMeta {
  model?: string;
  usage?: {
    prompt_tokens?: number;
    completion_tokens?: number;
    total_tokens?: number;
  };
  source?: 'chrome' | 'cloudflare';
  raw?: unknown; // ä¿ç•™åŸå§‹è¿”å›ï¼Œä¾¿äºè°ƒè¯•
}

export interface AiResponse {
  text: string;
  meta?: AiResponseMeta;
}

import { API_CONFIG, AI_CONFIG } from '../config/constants';
import { logger } from './logger';

// ç»Ÿä¸€è·å–å†…ç½®AIå¯¹è±¡
function getChromeAI(): any | null {
  const w: any = (typeof window !== 'undefined') ? window : {};
  const c: any = (typeof chrome !== 'undefined') ? chrome : {};
  return w.ai || c.ai || null;
}

// åˆ†å‘æŒ‡æ ‡äº‹ä»¶ï¼Œä¾¿äºUIæ˜¾ç¤ºå»¶è¿Ÿä¸tokenç”¨é‡
function emitAIMetrics(detail: {
  provider: 'chrome' | 'cloudflare';
  model?: string;
  latencyMs?: number;
  usage?: { prompt_tokens?: number; completion_tokens?: number; total_tokens?: number } | null;
}) {
  try {
    window.dispatchEvent(new CustomEvent('ai:metrics', { detail }));
  } catch {}
}

// åŸºäº Prompt API çš„æœ€ä½³å®è·µï¼šå¯ç”¨æ€§æ£€æŸ¥ + æ¨¡å‹åˆ›å»º + å¤ç”¨ä¼šè¯
let chromeAISession: any | null = null;
async function ensureChromeSession(options: AiCompleteOptions = {}): Promise<any | null> {
  try {
    const ai: any = getChromeAI();
    if (!ai) return null;

    // å¯ç”¨æ€§æ£€æµ‹ï¼ˆè‹¥æ”¯æŒï¼‰
    if (typeof ai.availability === 'function') {
      const status = await ai.availability();
      // Prompt APIå¸¸è§çŠ¶æ€ï¼š'readily' | 'after_download' | 'unsupported'
      if (status !== 'readily') return null;
    }

    // å¤ç”¨å·²æœ‰ä¼šè¯
    if (chromeAISession) return chromeAISession;

    // åˆ›å»ºè¯­è¨€æ¨¡å‹ä¼šè¯ï¼ˆè‹¥æ”¯æŒï¼‰
    if (typeof ai.create === 'function') {
      const temperature = options.temperature ?? AI_CONFIG.DEFAULT_TEMPERATURE;
      const topK = AI_CONFIG.DEFAULT_TOP_K;
      const maxTokens = options.maxTokens ?? AI_CONFIG.DEFAULT_MAX_TOKENS;
      const params: any = {
        temperature,
        topK,
        // Prompt APIé€šå¸¸ä½¿ç”¨ maxOutputTokens å‘½å
        maxOutputTokens: maxTokens,
        // å¯é€‰æ¨¡å‹åç§°
        model: AI_CONFIG.CHROME_MODEL,
        // åˆå§‹æç¤ºï¼ˆç³»ç»ŸæŒ‡ä»¤ï¼‰
        initialPrompts: AI_CONFIG.INITIAL_PROMPTS
      };

      chromeAISession = await ai.create(params);
      try {
        const detail = { provider: 'chrome', model: AI_CONFIG.CHROME_MODEL };
        window.dispatchEvent(new CustomEvent('ai:providerChanged', { detail }));
      } catch {}
      return chromeAISession;
    }

    return null;
  } catch (err) {
    logger.warn('ensureChromeSession åˆ›å»ºä¼šè¯å¤±è´¥:', err);
    return null;
  }
}

async function runSessionPrompt(session: any, text: string): Promise<string | null> {
  try {
    if (!session) return null;
    // å¸¸è§æ–¹æ³•åå…¼å®¹
    if (typeof session.prompt === 'function') {
      const res = await session.prompt(text);
      return (typeof res === 'string') ? res : (res?.text ?? res?.response ?? '') || null;
    }
    if (typeof session.output === 'function') {
      const res = await session.output({ text });
      return (typeof res === 'string') ? res : (res?.text ?? res?.response ?? '') || null;
    }
    if (typeof session.sendMessage === 'function') {
      const res = await session.sendMessage(text);
      return (typeof res === 'string') ? res : (res?.text ?? res?.response ?? '') || null;
    }
    return null;
  } catch (err) {
    logger.warn('runSessionPrompt æ‰§è¡Œå¤±è´¥:', err);
    return null;
  }
}

function getBaseUrl(): string {
  // ç»Ÿä¸€èµ°å…¨å±€ API é…ç½®ï¼Œé¿å…ç¯å¢ƒå˜é‡é”®åä¸ä¸€è‡´å¯¼è‡´çš„å›é€€åˆ°åŒæº
  // API_CONFIG ä¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¼˜å…ˆä½¿ç”¨ VITE_CLOUDFLARE_WORKER_URLï¼Œ
  // å¼€å‘ç¯å¢ƒä¼˜å…ˆä½¿ç”¨ VITE_API_BASE_URL æˆ– localhost
  return API_CONFIG.API_BASE || '';
}

async function safeFetchJson(url: string, init: RequestInit & { timeoutMs?: number } = {}): Promise<any> {
  const { timeoutMs = 15000, ...rest } = init;
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
  try {
    const resp = await fetch(url, {
      ...rest,
      headers: {
        'content-type': 'application/json',
        ...(rest.headers || {})
      },
      signal: rest.signal ?? controller.signal
    });
    if (!resp.ok) {
      const text = await resp.text().catch(() => '');
      throw new Error(`AI API HTTP ${resp.status}: ${text || resp.statusText}`);
    }
    return await resp.json();
  } finally {
    clearTimeout(timeoutId);
  }
}

function parseAiAnswer(answer: any): AiResponse {
  // Cloudflare Workers AI æ–‡æœ¬æ¨¡å‹é€šå¸¸è¿”å› { response: string, ... }
  let text = '';
  if (typeof answer === 'string') {
    text = answer;
  } else if (typeof answer?.response === 'string') {
    text = answer.response;
  } else if (typeof answer?.output_text === 'string') {
    text = answer.output_text;
  } else if (Array.isArray(answer?.choices) && answer.choices.length > 0) {
    const choice = answer.choices[0];
    text = choice?.message?.content || choice?.text || '';
  } else {
    // å…œåº•ï¼šåºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²ä¾¿äºå±•ç¤º
    text = JSON.stringify(answer);
  }

  const usage = answer?.usage || answer?.tokenUsage || undefined;
  const model = answer?.model || undefined;

  return {
    text,
    meta: {
      model,
      usage,
      source: 'cloudflare',
      raw: answer
    }
  };
}

function isChromeAIAvailable(): boolean {
  return !!getChromeAI();
}

async function callChromeComplete(prompt: string, options: AiCompleteOptions): Promise<AiResponse | null> {
  try {
    const ai: any = getChromeAI();
    if (!ai) return null;

    // å®½æ¾é€‚é…å¤šç§å¯èƒ½çš„å†…ç½®APIå‘½å
    const temperature = options.temperature ?? AI_CONFIG.DEFAULT_TEMPERATURE;
    const maxTokens = options.maxTokens ?? AI_CONFIG.DEFAULT_MAX_TOKENS;

    // ä¼˜å…ˆä½¿ç”¨ Prompt API ä¼šè¯
    const session = await ensureChromeSession(options);
    if (session) {
      const t0 = performance.now();
      const text = await runSessionPrompt(session, prompt);
      const latencyMs = performance.now() - t0;
      if (text != null) {
        emitAIMetrics({ provider: 'chrome', model: AI_CONFIG.CHROME_MODEL, latencyMs, usage: null });
        return { text, meta: { source: 'chrome', raw: { sessionUsed: true } } };
      }
    }

    let res: any;
    if (typeof ai.generateText === 'function') {
      const t0 = performance.now();
      res = await ai.generateText({ prompt, temperature, maxTokens });
      const text = (typeof res === 'string') ? res : (res?.text ?? res?.response ?? '');
      emitAIMetrics({ provider: 'chrome', model: AI_CONFIG.CHROME_MODEL, latencyMs: performance.now() - t0, usage: null });
      return { text: text || '', meta: { source: 'chrome', raw: res } };
    }
    if (typeof ai.invoke === 'function') {
      const t0 = performance.now();
      res = await ai.invoke({ prompt, temperature, maxTokens });
      const text = (typeof res === 'string') ? res : (res?.text ?? res?.response ?? '');
      emitAIMetrics({ provider: 'chrome', model: AI_CONFIG.CHROME_MODEL, latencyMs: performance.now() - t0, usage: null });
      return { text: text || '', meta: { source: 'chrome', raw: res } };
    }
    if (typeof ai.complete === 'function') {
      const t0 = performance.now();
      res = await ai.complete({ prompt, temperature, maxTokens });
      const text = (typeof res === 'string') ? res : (res?.text ?? res?.response ?? '');
      emitAIMetrics({ provider: 'chrome', model: AI_CONFIG.CHROME_MODEL, latencyMs: performance.now() - t0, usage: null });
      return { text: text || '', meta: { source: 'chrome', raw: res } };
    }
    if (typeof ai.run === 'function') {
      const t0 = performance.now();
      res = await ai.run({ prompt, temperature, maxTokens });
      const text = (typeof res === 'string') ? res : (res?.text ?? res?.response ?? '');
      emitAIMetrics({ provider: 'chrome', model: AI_CONFIG.CHROME_MODEL, latencyMs: performance.now() - t0, usage: null });
      return { text: text || '', meta: { source: 'chrome', raw: res } };
    }

    // Assistanté£æ ¼ä¼šè¯ï¼ˆè‹¥å¯ç”¨ï¼‰
    if (ai.assistant && typeof ai.assistant.create === 'function') {
      const session = await ai.assistant.create({ temperature });
      const output = await session.output({ text: prompt });
      const text = (typeof output === 'string') ? output : (output?.text ?? output?.response ?? '');
      return { text: text || '', meta: { source: 'chrome', raw: output } };
    }

    return null; // æœªåŒ¹é…åˆ°å¯ç”¨æ–¹æ³•
  } catch (err) {
    logger.warn('Chromeå†…ç½®AIè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°Cloudflare:', err);
    return null;
  }
}

async function callCloudflareComplete(prompt: string, options: AiCompleteOptions): Promise<AiResponse> {
  const base = getBaseUrl();
  const url = `${base}/api/ai/complete`;
  const body = {
    prompt,
    model: options.model ?? AI_CONFIG.CLOUDFLARE_DEFAULT_MODEL,
    temperature: options.temperature ?? 0.6,
    max_tokens: options.maxTokens ?? 256,
    stream: options.stream === true ? true : false
  };
  const t0 = performance.now();
  const answer = await safeFetchJson(url, {
    method: 'POST',
    body: JSON.stringify(body),
    signal: options.signal
  });
  const res = parseAiAnswer(answer);
  const latencyMs = performance.now() - t0;
  emitAIMetrics({ provider: 'cloudflare', model: res?.meta?.model || body.model, latencyMs, usage: res?.meta?.usage || null });
  return res;
}

async function callChromeChat(messages: AiMessage[], options: AiChatOptions): Promise<AiResponse | null> {
  try {
    const ai: any = getChromeAI();
    if (!ai) return null;

    const temperature = options.temperature ?? AI_CONFIG.DEFAULT_TEMPERATURE;
    const maxTokens = options.maxTokens ?? AI_CONFIG.DEFAULT_MAX_TOKENS;
    // ç®€åŒ–ä¸ºæ‹¼æ¥å†…å®¹ï¼›ä¼šè¯å·²ä½¿ç”¨ initialPrompts ä½œä¸ºç³»ç»ŸæŒ‡ä»¤
    const userText = messages.map(m => m.content).join('\n');

    // ä¼˜å…ˆä½¿ç”¨ Prompt API ä¼šè¯
    const session = await ensureChromeSession(options);
    if (session) {
      const t0 = performance.now();
      const text = await runSessionPrompt(session, userText);
      const latencyMs = performance.now() - t0;
      if (text != null) {
        emitAIMetrics({ provider: 'chrome', model: AI_CONFIG.CHROME_MODEL, latencyMs, usage: null });
        return { text, meta: { source: 'chrome', raw: { sessionUsed: true } } };
      }
    }

    // ä¼˜å…ˆä½¿ç”¨ä¸completeç›¸åŒçš„ä¸€ç»„æ–¹æ³•
    if (typeof ai.generateText === 'function') {
      const t0 = performance.now();
      const res = await ai.generateText({ prompt: userText, temperature, maxTokens });
      const text = (typeof res === 'string') ? res : (res?.text ?? res?.response ?? '');
      emitAIMetrics({ provider: 'chrome', model: AI_CONFIG.CHROME_MODEL, latencyMs: performance.now() - t0, usage: null });
      return { text: text || '', meta: { source: 'chrome', raw: res } };
    }
    if (typeof ai.invoke === 'function') {
      const t0 = performance.now();
      const res = await ai.invoke({ prompt: userText, temperature, maxTokens });
      const text = (typeof res === 'string') ? res : (res?.text ?? res?.response ?? '');
      emitAIMetrics({ provider: 'chrome', model: AI_CONFIG.CHROME_MODEL, latencyMs: performance.now() - t0, usage: null });
      return { text: text || '', meta: { source: 'chrome', raw: res } };
    }
    if (ai.assistant && typeof ai.assistant.create === 'function') {
      const t0 = performance.now();
      const session = await ai.assistant.create({ temperature });
      const output = await session.output({ text: userText });
      const text = (typeof output === 'string') ? output : (output?.text ?? output?.response ?? '');
      emitAIMetrics({ provider: 'chrome', model: AI_CONFIG.CHROME_MODEL, latencyMs: performance.now() - t0, usage: null });
      return { text: text || '', meta: { source: 'chrome', raw: output } };
    }

    return null;
  } catch (err) {
    console.warn('Chromeå†…ç½®AIèŠå¤©å¤±è´¥ï¼Œå›é€€åˆ°Cloudflare:', err);
    return null;
  }
}

async function callCloudflareChat(messages: AiMessage[], options: AiChatOptions): Promise<AiResponse> {
  const base = getBaseUrl();
  const url = `${base}/api/ai/complete`;
  const body = {
    messages,
    model: options.model ?? AI_CONFIG.CLOUDFLARE_DEFAULT_MODEL,
    temperature: options.temperature ?? 0.6,
    max_tokens: options.maxTokens ?? 256,
    stream: options.stream === true ? true : false
  };
  const t0 = performance.now();
  const answer = await safeFetchJson(url, {
    method: 'POST',
    body: JSON.stringify(body),
    signal: options.signal
  });
  const res = parseAiAnswer(answer);
  const latencyMs = performance.now() - t0;
  emitAIMetrics({ provider: 'cloudflare', model: res?.meta?.model || body.model, latencyMs, usage: res?.meta?.usage || null });
  return res;
}

export class UnifiedAIAPI {
  static async complete(prompt: string, options: AiCompleteOptions = {}): Promise<AiResponse> {
    if (!prompt || !prompt.trim()) {
      throw new Error('prompt ä¸èƒ½ä¸ºç©º');
    }
    const mode = AI_CONFIG.PROVIDER;
    if (mode === 'chrome' || (mode === 'auto' && isChromeAIAvailable())) {
      const chromeRes = await callChromeComplete(prompt, options);
      if (chromeRes && chromeRes.text) {
        logger.info('AI', 'Provider: chrome');
        try {
          const detail = { provider: 'chrome', model: AI_CONFIG.CHROME_MODEL };
          window.dispatchEvent(new CustomEvent('ai:providerChanged', { detail }));
        } catch {}
        return chromeRes;
      }
    }
    logger.info('AI', 'Provider: cloudflare');
    const cfRes = await callCloudflareComplete(prompt, options);
    try {
      const detail = { provider: 'cloudflare', model: cfRes?.meta?.model || (options.model ?? '@cf/meta/llama-3.1-8b-instruct') };
      window.dispatchEvent(new CustomEvent('ai:providerChanged', { detail }));
    } catch {}
    return cfRes;
  }

  static async chat(messages: AiMessage[], options: AiChatOptions = {}): Promise<AiResponse> {
    if (!Array.isArray(messages) || messages.length === 0) {
      throw new Error('messages ä¸èƒ½ä¸ºç©º');
    }
    const mode = AI_CONFIG.PROVIDER;
    if (mode === 'chrome' || (mode === 'auto' && isChromeAIAvailable())) {
      const chromeRes = await callChromeChat(messages, options);
      if (chromeRes && chromeRes.text) {
        logger.info('ğŸ§  [AI] Provider: chrome');
        try {
          const detail = { provider: 'chrome', model: AI_CONFIG.CHROME_MODEL };
          window.dispatchEvent(new CustomEvent('ai:providerChanged', { detail }));
        } catch {}
        return chromeRes;
      }
    }
    logger.info('ğŸ§  [AI] Provider: cloudflare');
    const cfRes = await callCloudflareChat(messages, options);
    try {
      const detail = { provider: 'cloudflare', model: cfRes?.meta?.model || (options.model ?? '@cf/meta/llama-3.1-8b-instruct') };
      window.dispatchEvent(new CustomEvent('ai:providerChanged', { detail }));
    } catch {}
    return cfRes;
  }

  // ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡ï¼ˆè°ƒç”¨åç«¯Cloudflare Workerç«¯ç‚¹ï¼‰
  static async embedding(text: string, options: { model?: string; signal?: AbortSignal } = {}): Promise<number[]> {
    if (!text || !text.trim()) {
      return [];
    }
    const base = getBaseUrl();
    const url = `${base}/api/ai/embedding`;
    const body = {
      text,
      model: options.model ?? '@cf/baai/bge-m3'
    };
    const answer = await safeFetchJson(url, {
      method: 'POST',
      body: JSON.stringify(body),
      signal: options.signal
    });
    // å…¼å®¹å¤šç§è¿”å›æ ¼å¼
    if (Array.isArray(answer)) return answer as number[];
    if (Array.isArray(answer?.data)) return answer.data as number[];
    if (Array.isArray(answer?.vector)) return answer.vector as number[];
    if (Array.isArray(answer?.response)) return answer.response as number[];
    if (Array.isArray(answer?.embeddings)) return answer.embeddings as number[];
    return [];
  }

  static async generateTags(title: string, content: string, options: AiCompleteOptions = {}): Promise<string[]> {
    if (!title && !content) {
      return [];
    }

    const prompt = `${AI_CONFIG.TAG_GENERATION_PROMPT}\n\nInput: "${title}", content: "${content.substring(0, 500)}..."`;

    try {
      const response = await this.complete(prompt, {
        ...options,
        temperature: 0.2, // Lower temperature for more deterministic output
        maxTokens: 64,    // Sufficient for a few tags
      });

      const text = response.text.trim();
      let tags: string[] = [];

      // Robustly parse the JSON array
      try {
        const parsed = JSON.parse(text);
        if (Array.isArray(parsed)) {
          tags = parsed.filter((tag: any) => typeof tag === 'string' && tag.length > 0);
        }
      } catch {
        // Fallback for non-JSON or malformed JSON responses
        tags = text.split(',').map(tag => tag.trim()).filter(tag => tag.length > 0);
      }

      return tags.slice(0, 3); // Limit to 3 tags
    } catch (error) {
      logger.error('Error generating tags:', error);
      return [];
    }
  }
}

export default UnifiedAIAPI;