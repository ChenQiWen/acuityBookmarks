/**
 * ğŸ¯ æœ¬åœ°çˆ¬è™«å·¥ä½œå™¨ - 100% å®¢æˆ·ç«¯æ‰§è¡Œ
 *
 * æ ¸å¿ƒç‰¹æ€§ï¼š
 * - å®Œå…¨åŸºäº Offscreen Document
 * - é›¶æ•°æ®ä¸Šä¼ ï¼Œä¿æŠ¤éšç§
 * - åŸŸåçº§åˆ«é™æµ
 * - Robots.txt å°Šé‡
 * - è¶…æ—¶æ§åˆ¶
 * - é”™è¯¯é™çº§
 *
 * @module LocalCrawlerWorker
 */

import { logger } from '@/infrastructure/logging/logger'
import { dispatchOffscreenRequest } from '@/background/offscreen-manager'
import { TIMEOUT_CONFIG } from '@/config/constants'

// ==================== ç±»å‹å®šä¹‰ ====================

export interface CrawlResult {
  success: boolean
  url: string
  httpStatus?: number
  metadata?: PageMetadata
  robotsAllowed?: boolean
  duration: number
  error?: string
  errorType?:
    | 'timeout'
    | 'cors'
    | 'network'
    | 'http_error'
    | 'robots'
    | 'unknown'
  retryCount?: number // é‡è¯•æ¬¡æ•°
}

export interface PageMetadata {
  // åŸºç¡€å­—æ®µ
  title: string
  description: string
  keywords: string
  lang: string
  author: string

  // Open Graph
  ogTitle: string
  ogDescription: string
  ogImage: string
  ogSiteName: string
  ogType: string

  // Twitter Card
  twitterCard: string
  twitterTitle: string
  twitterDescription: string
  twitterImage: string

  // å›¾æ ‡
  iconHref: string
}

export interface CrawlOptions {
  respectRobots?: boolean
  timeout?: number
  retryCount?: number
}

// ==================== é…ç½®å¸¸é‡ ====================

const MIN_DOMAIN_INTERVAL_MS = 1000 // åŸŸå†…è¯·æ±‚é—´éš” 1 ç§’ï¼Œé¿å…è¿‡äºæ¿€è¿›è§¦å‘é™æµ
// âœ… ä½¿ç”¨ç»Ÿä¸€é…ç½®ï¼šçˆ¬è™«è¯·æ±‚è¶…æ—¶
const REQUEST_TIMEOUT_MS = TIMEOUT_CONFIG.CRAWLER.REQUEST
const MAX_RETRIES = 2 // å¤±è´¥åæœ€å¤šè‡ªåŠ¨é‡è¯• 2 æ¬¡ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
const ROBOTS_CACHE_TTL = 24 * 60 * 60 * 1000 // Robots.txt ç¼“å­˜ 24 å°æ—¶ï¼Œå‡å°‘é¢‘ç¹è®¿é—®
const HEAD_SNIPPET_MAX_BYTES = 160 * 1024 // ä»…æŠ“å–å‰ 160KBï¼Œæé«˜é•¿æ–‡é¡µé¢çš„å“åº”é€Ÿåº¦
const REQUIRED_FIELD_THRESHOLD = 2 // éœ€è¦è‡³å°‘ä¸¤ä¸ªæ ¸å¿ƒå­—æ®µï¼Œç¡®ä¿æœ€ç»ˆæ•°æ®è´¨é‡

// ==================== ç¼“å­˜ ====================

const DOMAIN_LAST_ACCESS = new Map<string, number>()
const ROBOTS_CACHE = new Map<string, { allowed: boolean; timestamp: number }>()

// ==================== è¾…åŠ©å‡½æ•° ====================

/**
 * ä» URL æå–åŸŸå
 */
function getDomainFromURL(url: string): string {
  try {
    return new URL(url).hostname.toLowerCase()
  } catch {
    return ''
  }
}

/**
 * æŒ‰éœ€è¯»å– HTML ç‰‡æ®µ
 *
 * é€šè¿‡ ReadableStream è¾¹è¯»è¾¹è§£ç ï¼Œæ£€æµ‹åˆ° </head> æˆ–è€…è¶…è¿‡ä¸Šé™åç«‹å³åœæ­¢ï¼Œ
 * é¿å…æŠŠæ•´é¡µæ­£æ–‡ä¸‹è½½å®Œæ¯•ï¼Œæ˜¾è‘—å‡å°‘ç½‘ç»œä¸è§£æå¼€é”€ã€‚
 */
async function readHeadHtmlSnippet(
  response: Response,
  maxBytes: number = HEAD_SNIPPET_MAX_BYTES
): Promise<string> {
  if (!response.body) {
    return await response.text()
  }

  const reader = response.body.getReader()
  const decoder = new TextDecoder('utf-8') // Chrome é»˜è®¤ UTF-8ï¼Œå¯æ ¹æ® meta charset åœ¨åç»­æ‰©å±•
  let html = ''
  let bytesRead = 0
  let headClosed = false

  try {
    while (true) {
      const { value, done } = await reader.read()
      if (done) break

      bytesRead += value.byteLength
      html += decoder.decode(value, { stream: true })

      if (html.toLowerCase().includes('</head>')) {
        headClosed = true
        break
      }

      if (bytesRead >= maxBytes) {
        break
      }
    }
  } finally {
    html += decoder.decode()

    if (!headClosed) {
      try {
        await reader.cancel()
      } catch {
        // å¿½ç•¥å–æ¶ˆå¤±è´¥
      }
    }
  }

  return html
}

/**
 * åˆ¤æ–­åŸºç¡€å…ƒæ•°æ®æ˜¯å¦å·²ç»å……è¶³
 *
 * åªè¦ Title / Description / og:site_name è‡³å°‘æ»¡è¶³ä¸¤ä¸ªï¼Œå°±è®¤ä¸ºæ­£åˆ™è§£æè¶³å¤Ÿï¼Œ
 * å¯ä»¥è·³è¿‡ Offscreen DOM æ¸²æŸ“ï¼ŒèŠ‚çœä¸€æ¬¡æ¶ˆæ¯å¾€è¿”ã€‚
 */
function metadataHasEssentialFields(meta: PageMetadata): boolean {
  let essentials = 0
  if (meta.title || meta.ogTitle) essentials += 1
  if (meta.description || meta.ogDescription) essentials += 1
  if (meta.ogSiteName) essentials += 1

  return essentials >= REQUIRED_FIELD_THRESHOLD
}

/**
 * åˆå¹¶å…ƒæ•°æ®
 *
 * ä»¥æ­£åˆ™ç»“æœä¸ºä¸»ï¼Œé€å­—æ®µè¡¥å…… Offscreen è§£æå¾—åˆ°çš„å†…å®¹ï¼Œ
 * é¿å…è¦†ç›–å·²æœ‰çš„éç©ºæ•°æ®ï¼Œä¿è¯ç»“æœç¨³å®šå¯æ§ã€‚
 */
function mergeMetadata(
  base: PageMetadata,
  extra?: Partial<PageMetadata>
): PageMetadata {
  if (!extra) return base
  const sanitized: Partial<PageMetadata> = {}
  for (const [key, value] of Object.entries(extra)) {
    if (value !== undefined && value !== null && value !== '') {
      sanitized[key as keyof PageMetadata] =
        value as PageMetadata[keyof PageMetadata]
    }
  }
  return { ...base, ...sanitized }
}

/**
 * ä¸»åŠ¨ä¸¢å¼ƒå‰©ä½™å“åº”ä½“
 *
 * åœ¨å·²ç»æå‰æˆªæ–­ HEAD åï¼Œå–æ¶ˆåº•å±‚æµè¯»å–ï¼Œé¿å…ä¿æŒç½‘ç»œè¿æ¥å ç”¨èµ„æºã€‚
 */
async function discardResponseBody(response: Response): Promise<void> {
  if (response.body) {
    try {
      await response.body.cancel()
    } catch {
      // å¿½ç•¥å–æ¶ˆå¼‚å¸¸
    }
    return
  }

  try {
    await response.arrayBuffer()
  } catch {
    // å¿½ç•¥
  }
}

/**
 * æ„é€ å¯ä¾› Offscreen DOM æ­£å¸¸è§£æçš„æœ€å° HTML
 *
 * æœ‰äº›ç«™ç‚¹çš„ head ç‰‡æ®µä¸æˆå¯¹ï¼Œæ­¤å‡½æ•°å°†å…¶åŒ…è£…è¿›å®Œæ•´æ–‡æ¡£ç»“æ„ï¼Œ
 * ç¡®ä¿ DOMParser ä¸æŠ¥é”™ã€‚
 */
/**
 * æå– head æ ¸å¿ƒç‰‡æ®µ
 *
 * - å¦‚æœæŠ“åˆ°å®Œæ•´çš„ `<head> ... </head>`ï¼Œåˆ™ç›´æ¥è¿”å›å†…éƒ¨å†…å®¹
 * - å¦‚æœåªæœ‰ `<head>` èµ·å§‹æ ‡ç­¾æˆ–æ ¹æœ¬æ²¡æœ‰ `<head>`ï¼Œåˆ™ä»…ä¿ç•™ `<head>` å‰éƒ¨ä»½
 *
 * è¿™æ ·ä¸€æ¥ï¼Œæˆ‘ä»¬åªä¼šä¼ é€’æœ‰é™çš„ head ç‰‡æ®µç»™ Offscreenï¼Œé¿å…å°†æ­£æ–‡éƒ¨åˆ†åŒ…è¿›å»ã€‚
 */
function extractHeadContent(html: string): string {
  const lower = html.toLowerCase()
  const headStartMatch = lower.match(/<head[^>]*>/)
  if (!headStartMatch) {
    const headEndIndex = lower.indexOf('</head>')
    if (headEndIndex !== -1) {
      return html.slice(0, headEndIndex)
    }

    const headlessEndIndex = Math.max(
      lower.indexOf('<body'),
      lower.indexOf('<div'),
      lower.indexOf('<p')
    )

    if (headlessEndIndex !== -1) {
      return html.slice(0, headlessEndIndex)
    }

    return html
  }

  const headStartIndex = headStartMatch.index ?? 0
  const afterHead = html.slice(headStartIndex + headStartMatch[0].length)
  const headEndIndex = afterHead.toLowerCase().indexOf('</head>')

  if (headEndIndex !== -1) {
    return afterHead.slice(0, headEndIndex)
  }

  const bodyIndex = afterHead.toLowerCase().indexOf('<body')
  if (bodyIndex !== -1) {
    return afterHead.slice(0, bodyIndex)
  }

  return afterHead
}

function ensureDomParsableSnippet(html: string): string {
  const trimmed = html.trim()
  if (!trimmed) {
    return '<!doctype html><html><head></head><body></body></html>'
  }

  const headContent = extractHeadContent(trimmed)
  return `<!doctype html><html><head>${headContent}</head><body></body></html>`
}

/**
 * ä½¿ç”¨ Offscreen æ–‡æ¡£è§£æï¼Œå¹¶åœ¨å¤±è´¥æ—¶å›é€€
 *
 * å…ˆå°è¯•é«˜çº§è§£æï¼Œè‹¥æˆåŠŸåˆ™ä¸æ­£åˆ™ç»“æœåˆå¹¶ï¼›è‹¥å¤±è´¥ï¼Œä¿ç•™æ­£åˆ™ç»“æœå¹¶æ‰“æ—¥å¿—ã€‚
 */
async function parseWithOffscreenOrFallback(
  htmlSnippet: string,
  url: string,
  fallback: PageMetadata
): Promise<PageMetadata> {
  try {
    const sanitized = ensureDomParsableSnippet(htmlSnippet)
    const parsed = await parseHTMLInOffscreen(sanitized, url)
    logger.debug('LocalCrawler', `âœ… Offscreen è§£æè¡¥å……: ${url}`)
    return mergeMetadata(fallback, parsed)
  } catch (offscreenError) {
    logger.warn('LocalCrawler', `âš ï¸ Offscreen è§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™ç»“æœ: ${url}`, {
      error: offscreenError
    })
    return fallback
  }
}

/**
 * ç­‰å¾…åŸŸåæ—¶é—´æ§½
 */
async function waitForDomainSlot(domain: string): Promise<void> {
  const lastAccess = DOMAIN_LAST_ACCESS.get(domain) || 0
  const now = Date.now()
  const diff = now - lastAccess

  if (diff < MIN_DOMAIN_INTERVAL_MS) {
    const waitTime = MIN_DOMAIN_INTERVAL_MS - diff
    await new Promise(resolve => setTimeout(resolve, waitTime))
  }

  DOMAIN_LAST_ACCESS.set(domain, Date.now())
}

/**
 * æ£€æŸ¥ Robots.txt
 */
async function checkRobotsTxt(url: string): Promise<boolean> {
  const domain = getDomainFromURL(url)
  if (!domain) return true

  // æ£€æŸ¥ç¼“å­˜
  const cached = ROBOTS_CACHE.get(domain)
  if (cached && Date.now() - cached.timestamp < ROBOTS_CACHE_TTL) {
    return cached.allowed
  }

  try {
    const robotsUrl = `https://${domain}/robots.txt`
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), 5000)

    const response = await fetch(robotsUrl, {
      signal: controller.signal,
      headers: {
        'User-Agent': 'AcuityBookmarks-Extension/1.0'
      }
    })

    clearTimeout(timeoutId)

    let allowed = true

    if (response.ok) {
      const text = await response.text()

      // ç®€åŒ–è§£æï¼šæ£€æŸ¥æ˜¯å¦æœ‰ User-agent: * + Disallow: /
      if (/User-agent:\s*\*/i.test(text) && /Disallow:\s*\//i.test(text)) {
        allowed = false
      }
    }

    // ç¼“å­˜ç»“æœ
    ROBOTS_CACHE.set(domain, { allowed, timestamp: Date.now() })
    return allowed
  } catch (error) {
    // æ— æ³•è·å–åˆ™é»˜è®¤å…è®¸
    logger.debug(
      'LocalCrawler',
      `Failed to check robots.txt for ${domain}`,
      error
    )
    ROBOTS_CACHE.set(domain, { allowed: true, timestamp: Date.now() })
    return true
  }
}

/**
 * ä½¿ç”¨ Offscreen Document è§£æ HTML
 */
async function parseHTMLInOffscreen(
  html: string,
  url: string
): Promise<PageMetadata> {
  const fallback = fallbackParseHTML(html)

  try {
    const offscreenResult = await dispatchOffscreenRequest<
      Partial<PageMetadata>
    >(
      {
        type: 'PARSE_HTML',
        payload: { html, url }
      },
      { timeout: TIMEOUT_CONFIG.CRAWLER.PARSE } // HTMLè§£æè¶…æ—¶
    )

    return mergeMetadata(fallback, offscreenResult)
  } catch (error) {
    logger.warn('LocalCrawler', 'Offscreen è§£æå¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ', error)
    return fallback
  }
}

/**
 * é™çº§ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ HTML
 */
function fallbackParseHTML(html: string): PageMetadata {
  const extract = (regex: RegExp): string => {
    const match = html.match(regex)
    return match ? match[1].trim() : ''
  }

  return {
    // åŸºç¡€
    title: extract(/<title[^>]*>([^<]*)<\/title>/i),
    description: extract(
      /<meta[^>]*name=["']description["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    keywords: extract(
      /<meta[^>]*name=["']keywords["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    lang: extract(/<html[^>]*lang=["']([^"']+)["'][^>]*>/i),
    author: extract(
      /<meta[^>]*name=["']author["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),

    // Open Graph
    ogTitle: extract(
      /<meta[^>]*property=["']og:title["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    ogDescription: extract(
      /<meta[^>]*property=["']og:description["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    ogImage: extract(
      /<meta[^>]*property=["']og:image["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    ogSiteName: extract(
      /<meta[^>]*property=["']og:site_name["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    ogType: extract(
      /<meta[^>]*property=["']og:type["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),

    // Twitter Card
    twitterCard: extract(
      /<meta[^>]*name=["']twitter:card["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    twitterTitle: extract(
      /<meta[^>]*name=["']twitter:title["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    twitterDescription: extract(
      /<meta[^>]*name=["']twitter:description["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    twitterImage: extract(
      /<meta[^>]*name=["']twitter:image["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),

    // å›¾æ ‡
    iconHref: extract(
      /<link[^>]*rel=["'](?:icon|shortcut icon|apple-touch-icon)["'][^>]*href=["']([^"']+)["'][^>]*>/i
    )
  }
}

/**
 * é”™è¯¯åˆ†ç±»
 */
function classifyError(error: unknown): CrawlResult['errorType'] {
  const message = error instanceof Error ? error.message : String(error)

  if (message.includes('aborted') || message.includes('timeout')) {
    return 'timeout'
  }
  if (message.includes('CORS') || message.includes('blocked')) {
    return 'cors'
  }
  if (message.includes('Failed to fetch') || message.includes('NetworkError')) {
    return 'network'
  }
  if (/HTTP [45]\d{2}/.test(message)) {
    return 'http_error'
  }
  if (message.includes('robots')) {
    return 'robots'
  }

  return 'unknown'
}

/**
 * åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•
 */
function shouldRetry(result: CrawlResult): boolean {
  return result.errorType === 'timeout' || result.errorType === 'network'
}

// ==================== æ ¸å¿ƒçˆ¬å–å‡½æ•° ====================

/**
 * æœ¬åœ°çˆ¬å–ä¹¦ç­¾
 *
 * @param url - ç›®æ ‡ URL
 * @param options - çˆ¬å–é€‰é¡¹
 * @returns çˆ¬å–ç»“æœ
 */
export async function crawlBookmarkLocally(
  url: string,
  options: CrawlOptions = {}
): Promise<CrawlResult> {
  const {
    respectRobots = true,
    timeout = REQUEST_TIMEOUT_MS,
    retryCount = 0
  } = options

  const startTime = Date.now()
  const domain = getDomainFromURL(url)

  try {
    // Step 1: åŸŸåé™æµ
    await waitForDomainSlot(domain)

    // Step 2: Robots.txt æ£€æŸ¥
    if (respectRobots) {
      const robotsAllowed = await checkRobotsTxt(url)
      if (!robotsAllowed) {
        return {
          success: false,
          url,
          error: 'Blocked by robots.txt',
          errorType: 'robots',
          robotsAllowed: false,
          duration: Date.now() - startTime
        }
      }
    }

    // Step 3: å‘èµ·ç½‘ç»œè¯·æ±‚
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), timeout)

    const response = await fetch(url, {
      method: 'GET',
      redirect: 'follow',
      signal: controller.signal,
      headers: {
        'User-Agent':
          'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        Accept:
          'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Cache-Control': 'no-cache'
      }
    })

    clearTimeout(timeoutId)

    // Step 4: æ£€æŸ¥å“åº”
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`)
    }

    const contentType = response.headers.get('content-type') || ''
    if (!/text\/html|application\/xhtml\+xml/i.test(contentType)) {
      throw new Error(`Unsupported content type: ${contentType}`)
    }

    // Step 5: è¯»å– HTML
    const htmlSnippet = await readHeadHtmlSnippet(response)

    if (!htmlSnippet || htmlSnippet.length < 50) {
      throw new Error('HTML content too short or empty')
    }

    // Step 6: æ­£åˆ™ä¼˜å…ˆè§£æ head å…ƒæ•°æ®
    const fallbackMetadata = fallbackParseHTML(htmlSnippet)

    let metadata: PageMetadata = fallbackMetadata

    if (!metadataHasEssentialFields(fallbackMetadata)) {
      logger.debug('LocalCrawler', `ğŸ§ª æ­£åˆ™ç»“æœä¸è¶³ï¼Œå‡†å¤‡ Offscreen: ${url}`)
      metadata = await parseWithOffscreenOrFallback(
        htmlSnippet,
        url,
        fallbackMetadata
      )
    }

    await discardResponseBody(response)

    // Step 7: è¿”å›æˆåŠŸç»“æœ
    return {
      success: true,
      url: response.url || url, // å¤„ç†é‡å®šå‘
      httpStatus: response.status,
      metadata,
      robotsAllowed: true,
      duration: Date.now() - startTime
    }
  } catch (error) {
    // é‡è¯•é€»è¾‘
    if (retryCount < MAX_RETRIES) {
      const result: CrawlResult = {
        success: false,
        url,
        error: error instanceof Error ? error.message : String(error),
        errorType: classifyError(error),
        duration: Date.now() - startTime,
        retryCount
      }

      if (shouldRetry(result)) {
        logger.debug(
          'LocalCrawler',
          `ğŸ”„ é‡è¯• (${retryCount + 1}/${MAX_RETRIES}): ${url}`
        )

        // ç­‰å¾…åé‡è¯•
        await new Promise(resolve =>
          setTimeout(resolve, 1000 * (retryCount + 1))
        )

        return crawlBookmarkLocally(url, {
          ...options,
          retryCount: retryCount + 1
        })
      }
    }

    // è¿”å›å¤±è´¥ç»“æœï¼ˆåŒ…å«æœ€ç»ˆçš„é‡è¯•æ¬¡æ•°ï¼‰
    return {
      success: false,
      url,
      error: error instanceof Error ? error.message : String(error),
      errorType: classifyError(error),
      duration: Date.now() - startTime,
      retryCount // âœ… æ·»åŠ é‡è¯•æ¬¡æ•°
    }
  }
}

// ==================== å·¥å…·å‡½æ•° ====================

/**
 * è·å–çˆ¬è™«ç»Ÿè®¡ä¿¡æ¯
 */
export function getCrawlerStats() {
  return {
    domainsCached: DOMAIN_LAST_ACCESS.size,
    robotsCached: ROBOTS_CACHE.size
  }
}

/**
 * æ¸…ç†ç¼“å­˜
 */
export function clearCrawlerCache() {
  DOMAIN_LAST_ACCESS.clear()
  ROBOTS_CACHE.clear()
  logger.info('LocalCrawler', 'ğŸ§¹ ç¼“å­˜å·²æ¸…ç†')
}

/**
 * é¢„çƒ­ Offscreen Document
 */
export async function warmupOffscreenDocument(): Promise<boolean> {
  try {
    // This function is no longer needed as Offscreen Document is managed by offscreen-manager
    // and the parsing is handled within crawlBookmarkLocally.
    // Keeping it for now, but it might be removed if not used elsewhere.
    logger.info(
      'LocalCrawler',
      'Offscreen Document warmup is no longer needed here.'
    )
    return true
  } catch (error) {
    logger.error('LocalCrawler', 'âŒ Offscreen Document é¢„çƒ­å¤±è´¥', error)
    return false
  }
}
