/**
 * ğŸ¯ æœ¬åœ°çˆ¬è™«å·¥ä½œå™¨ - 100% å®¢æˆ·ç«¯æ‰§è¡Œ
 *
 * æ ¸å¿ƒç‰¹æ€§ï¼š
 * - å®Œå…¨åŸºäº Offscreen Document
 * - é›¶æ•°æ®ä¸Šä¼ ï¼Œä¿æŠ¤éšç§
 * - åŸŸåçº§åˆ«é™æµ
 * - Robots.txt å°Šé‡
 * - è¶…æ—¶æ§åˆ¶
 * - é”™è¯¯é™çº§
 *
 * @module LocalCrawlerWorker
 */

import { logger } from '@/infrastructure/logging/logger'

// ==================== ç±»å‹å®šä¹‰ ====================

export interface CrawlResult {
  success: boolean
  url: string
  httpStatus?: number
  metadata?: PageMetadata
  robotsAllowed?: boolean
  duration: number
  error?: string
  errorType?:
    | 'timeout'
    | 'cors'
    | 'network'
    | 'http_error'
    | 'robots'
    | 'unknown'
}

export interface PageMetadata {
  // åŸºç¡€å­—æ®µ
  title: string
  description: string
  keywords: string
  lang: string
  author: string

  // Open Graph
  ogTitle: string
  ogDescription: string
  ogImage: string
  ogSiteName: string
  ogType: string

  // Twitter Card
  twitterCard: string
  twitterTitle: string
  twitterDescription: string
  twitterImage: string

  // å›¾æ ‡
  iconHref: string
}

export interface CrawlOptions {
  respectRobots?: boolean
  timeout?: number
  retryCount?: number
}

// ==================== é…ç½®å¸¸é‡ ====================

const MIN_DOMAIN_INTERVAL_MS = 1000 // åŸŸåé—´éš”1ç§’
const REQUEST_TIMEOUT_MS = 10000 // è¯·æ±‚è¶…æ—¶10ç§’
const MAX_RETRIES = 2 // æœ€å¤šé‡è¯•2æ¬¡
const ROBOTS_CACHE_TTL = 24 * 60 * 60 * 1000 // Robots.txt ç¼“å­˜24å°æ—¶

// ==================== ç¼“å­˜ ====================

const DOMAIN_LAST_ACCESS = new Map<string, number>()
const ROBOTS_CACHE = new Map<string, { allowed: boolean; timestamp: number }>()

// ==================== è¾…åŠ©å‡½æ•° ====================

/**
 * ä» URL æå–åŸŸå
 */
function getDomainFromURL(url: string): string {
  try {
    return new URL(url).hostname.toLowerCase()
  } catch {
    return ''
  }
}

/**
 * ç­‰å¾…åŸŸåæ—¶é—´æ§½
 */
async function waitForDomainSlot(domain: string): Promise<void> {
  const lastAccess = DOMAIN_LAST_ACCESS.get(domain) || 0
  const now = Date.now()
  const diff = now - lastAccess

  if (diff < MIN_DOMAIN_INTERVAL_MS) {
    const waitTime = MIN_DOMAIN_INTERVAL_MS - diff
    await new Promise(resolve => setTimeout(resolve, waitTime))
  }

  DOMAIN_LAST_ACCESS.set(domain, Date.now())
}

/**
 * æ£€æŸ¥ Robots.txt
 */
async function checkRobotsTxt(url: string): Promise<boolean> {
  const domain = getDomainFromURL(url)
  if (!domain) return true

  // æ£€æŸ¥ç¼“å­˜
  const cached = ROBOTS_CACHE.get(domain)
  if (cached && Date.now() - cached.timestamp < ROBOTS_CACHE_TTL) {
    return cached.allowed
  }

  try {
    const robotsUrl = `https://${domain}/robots.txt`
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), 5000)

    const response = await fetch(robotsUrl, {
      signal: controller.signal,
      headers: {
        'User-Agent': 'AcuityBookmarks-Extension/1.0'
      }
    })

    clearTimeout(timeoutId)

    let allowed = true

    if (response.ok) {
      const text = await response.text()

      // ç®€åŒ–è§£æï¼šæ£€æŸ¥æ˜¯å¦æœ‰ User-agent: * + Disallow: /
      if (/User-agent:\s*\*/i.test(text) && /Disallow:\s*\//i.test(text)) {
        allowed = false
      }
    }

    // ç¼“å­˜ç»“æœ
    ROBOTS_CACHE.set(domain, { allowed, timestamp: Date.now() })
    return allowed
  } catch (error) {
    // æ— æ³•è·å–åˆ™é»˜è®¤å…è®¸
    logger.debug(
      'LocalCrawler',
      `Failed to check robots.txt for ${domain}`,
      error
    )
    ROBOTS_CACHE.set(domain, { allowed: true, timestamp: Date.now() })
    return true
  }
}

/**
 * ç¡®ä¿ Offscreen Document å­˜åœ¨
 */
async function ensureOffscreenDocument(): Promise<boolean> {
  try {
    // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if (
      chrome.offscreen &&
      typeof chrome.offscreen.hasDocument === 'function'
    ) {
      const hasDoc = await chrome.offscreen.hasDocument()
      if (hasDoc) return true
    }
  } catch (e) {
    // hasDocument å¯èƒ½ä¸å­˜åœ¨ï¼Œç»§ç»­å°è¯•åˆ›å»º
    logger.debug('LocalCrawler', 'Offscreen Document not available', e)
  }

  try {
    await chrome.offscreen.createDocument({
      url: 'offscreen.html',
      reasons: ['DOM_SCRAPING' as chrome.offscreen.Reason],
      justification:
        'Parse bookmark page metadata locally for privacy protection'
    })

    logger.info('LocalCrawler', 'âœ… Offscreen Document å·²åˆ›å»º')
    return true
  } catch (error) {
    logger.error('LocalCrawler', 'âŒ æ— æ³•åˆ›å»º Offscreen Document', error)
    return false
  }
}

/**
 * ä½¿ç”¨ Offscreen Document è§£æ HTML
 */
async function parseHTMLInOffscreen(
  html: string,
  url: string
): Promise<PageMetadata> {
  const offscreenReady = await ensureOffscreenDocument()

  if (!offscreenReady) {
    throw new Error('Offscreen Document not available')
  }

  return new Promise((resolve, reject) => {
    const timeout = setTimeout(() => {
      reject(new Error('Offscreen parsing timeout'))
    }, 3000)

    chrome.runtime.sendMessage(
      { type: 'PARSE_HTML', html, url },
      (response: PageMetadata) => {
        clearTimeout(timeout)

        if (chrome.runtime.lastError) {
          reject(new Error(chrome.runtime.lastError.message))
          return
        }

        resolve(response || ({} as PageMetadata))
      }
    )
  })
}

/**
 * é™çº§ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ HTML
 */
function fallbackParseHTML(html: string): PageMetadata {
  const extract = (regex: RegExp): string => {
    const match = html.match(regex)
    return match ? match[1].trim() : ''
  }

  return {
    // åŸºç¡€
    title: extract(/<title[^>]*>([^<]*)<\/title>/i),
    description: extract(
      /<meta[^>]*name=["']description["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    keywords: extract(
      /<meta[^>]*name=["']keywords["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    lang: extract(/<html[^>]*lang=["']([^"']+)["'][^>]*>/i),
    author: extract(
      /<meta[^>]*name=["']author["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),

    // Open Graph
    ogTitle: extract(
      /<meta[^>]*property=["']og:title["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    ogDescription: extract(
      /<meta[^>]*property=["']og:description["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    ogImage: extract(
      /<meta[^>]*property=["']og:image["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    ogSiteName: extract(
      /<meta[^>]*property=["']og:site_name["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    ogType: extract(
      /<meta[^>]*property=["']og:type["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),

    // Twitter Card
    twitterCard: extract(
      /<meta[^>]*name=["']twitter:card["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    twitterTitle: extract(
      /<meta[^>]*name=["']twitter:title["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    twitterDescription: extract(
      /<meta[^>]*name=["']twitter:description["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),
    twitterImage: extract(
      /<meta[^>]*name=["']twitter:image["'][^>]*content=["']([^"']+)["'][^>]*>/i
    ),

    // å›¾æ ‡
    iconHref: extract(
      /<link[^>]*rel=["'](?:icon|shortcut icon|apple-touch-icon)["'][^>]*href=["']([^"']+)["'][^>]*>/i
    )
  }
}

/**
 * é”™è¯¯åˆ†ç±»
 */
function classifyError(error: unknown): CrawlResult['errorType'] {
  const message = error instanceof Error ? error.message : String(error)

  if (message.includes('aborted') || message.includes('timeout')) {
    return 'timeout'
  }
  if (message.includes('CORS') || message.includes('blocked')) {
    return 'cors'
  }
  if (message.includes('Failed to fetch') || message.includes('NetworkError')) {
    return 'network'
  }
  if (/HTTP [45]\d{2}/.test(message)) {
    return 'http_error'
  }
  if (message.includes('robots')) {
    return 'robots'
  }

  return 'unknown'
}

/**
 * åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•
 */
function shouldRetry(result: CrawlResult): boolean {
  return result.errorType === 'timeout' || result.errorType === 'network'
}

// ==================== æ ¸å¿ƒçˆ¬å–å‡½æ•° ====================

/**
 * æœ¬åœ°çˆ¬å–ä¹¦ç­¾
 *
 * @param url - ç›®æ ‡ URL
 * @param options - çˆ¬å–é€‰é¡¹
 * @returns çˆ¬å–ç»“æœ
 */
export async function crawlBookmarkLocally(
  url: string,
  options: CrawlOptions = {}
): Promise<CrawlResult> {
  const {
    respectRobots = true,
    timeout = REQUEST_TIMEOUT_MS,
    retryCount = 0
  } = options

  const startTime = Date.now()
  const domain = getDomainFromURL(url)

  try {
    // Step 1: åŸŸåé™æµ
    await waitForDomainSlot(domain)

    // Step 2: Robots.txt æ£€æŸ¥
    if (respectRobots) {
      const robotsAllowed = await checkRobotsTxt(url)
      if (!robotsAllowed) {
        return {
          success: false,
          url,
          error: 'Blocked by robots.txt',
          errorType: 'robots',
          robotsAllowed: false,
          duration: Date.now() - startTime
        }
      }
    }

    // Step 3: å‘èµ·ç½‘ç»œè¯·æ±‚
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), timeout)

    const response = await fetch(url, {
      method: 'GET',
      redirect: 'follow',
      signal: controller.signal,
      headers: {
        'User-Agent':
          'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        Accept:
          'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Cache-Control': 'no-cache'
      }
    })

    clearTimeout(timeoutId)

    // Step 4: æ£€æŸ¥å“åº”
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`)
    }

    const contentType = response.headers.get('content-type') || ''
    if (!/text\/html|application\/xhtml\+xml/i.test(contentType)) {
      throw new Error(`Unsupported content type: ${contentType}`)
    }

    // Step 5: è¯»å– HTML
    const html = await response.text()

    if (!html || html.length < 50) {
      throw new Error('HTML content too short or empty')
    }

    // Step 6: è§£æå…ƒæ•°æ®ï¼ˆä¼˜å…ˆ Offscreenï¼Œå¤±è´¥åˆ™é™çº§ï¼‰
    let metadata: PageMetadata
    try {
      metadata = await parseHTMLInOffscreen(html, url)
      logger.debug('LocalCrawler', `âœ… Offscreen è§£ææˆåŠŸ: ${url}`)
    } catch (offscreenError) {
      logger.warn(
        'LocalCrawler',
        `âš ï¸ Offscreen è§£æå¤±è´¥ï¼Œé™çº§åˆ°æ­£åˆ™: ${url}`,
        offscreenError
      )
      metadata = fallbackParseHTML(html)
    }

    // Step 7: è¿”å›æˆåŠŸç»“æœ
    return {
      success: true,
      url: response.url || url, // å¤„ç†é‡å®šå‘
      httpStatus: response.status,
      metadata,
      robotsAllowed: true,
      duration: Date.now() - startTime
    }
  } catch (error) {
    // é‡è¯•é€»è¾‘
    if (retryCount < MAX_RETRIES) {
      const result: CrawlResult = {
        success: false,
        url,
        error: error instanceof Error ? error.message : String(error),
        errorType: classifyError(error),
        duration: Date.now() - startTime
      }

      if (shouldRetry(result)) {
        logger.debug(
          'LocalCrawler',
          `ğŸ”„ é‡è¯• (${retryCount + 1}/${MAX_RETRIES}): ${url}`
        )

        // ç­‰å¾…åé‡è¯•
        await new Promise(resolve =>
          setTimeout(resolve, 1000 * (retryCount + 1))
        )

        return crawlBookmarkLocally(url, {
          ...options,
          retryCount: retryCount + 1
        })
      }
    }

    // è¿”å›å¤±è´¥ç»“æœ
    return {
      success: false,
      url,
      error: error instanceof Error ? error.message : String(error),
      errorType: classifyError(error),
      duration: Date.now() - startTime
    }
  }
}

// ==================== å·¥å…·å‡½æ•° ====================

/**
 * è·å–çˆ¬è™«ç»Ÿè®¡ä¿¡æ¯
 */
export function getCrawlerStats() {
  return {
    domainsCached: DOMAIN_LAST_ACCESS.size,
    robotsCached: ROBOTS_CACHE.size
  }
}

/**
 * æ¸…ç†ç¼“å­˜
 */
export function clearCrawlerCache() {
  DOMAIN_LAST_ACCESS.clear()
  ROBOTS_CACHE.clear()
  logger.info('LocalCrawler', 'ğŸ§¹ ç¼“å­˜å·²æ¸…ç†')
}

/**
 * é¢„çƒ­ Offscreen Document
 */
export async function warmupOffscreenDocument(): Promise<boolean> {
  try {
    const ready = await ensureOffscreenDocument()
    if (ready) {
      logger.info('LocalCrawler', 'ğŸ”¥ Offscreen Document é¢„çƒ­å®Œæˆ')
    }
    return ready
  } catch (error) {
    logger.error('LocalCrawler', 'âŒ Offscreen Document é¢„çƒ­å¤±è´¥', error)
    return false
  }
}
