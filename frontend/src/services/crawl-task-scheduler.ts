/**
 * ğŸ¯ æœ¬åœ°åŒ–çˆ¬å–ä»»åŠ¡è°ƒåº¦å™¨
 *
 * æ ¸å¿ƒåŠŸèƒ½ï¼š
 * - ä¼˜å…ˆçº§é˜Ÿåˆ—ç®¡ç†
 * - å¹¶å‘æ§åˆ¶ï¼ˆå…¨å±€ + åŸŸåçº§åˆ«ï¼‰
 * - ç©ºé—²è°ƒåº¦ï¼ˆä¸å½±å“ç”¨æˆ·ä½“éªŒï¼‰
 * - æ–­ç‚¹ç»­çˆ¬ï¼ˆæŒä¹…åŒ–çŠ¶æ€ï¼‰
 * - æ¸è¿›å¼æ•°æ®åŒæ­¥
 *
 * éšç§ä¿æŠ¤ï¼š
 * - 100% æœ¬åœ°æ‰§è¡Œ
 * - é›¶æ•°æ®ä¸Šä¼ 
 * - ä½¿ç”¨ Offscreen Document è§£æ
 */

import { logger } from '@/infrastructure/logging/logger'
import { CRAWLER_CONFIG } from '@/config/constants'
import { crawlBookmarkLocally, type CrawlResult } from './local-crawler-worker'

// ==================== ç±»å‹å®šä¹‰ ====================

export interface CrawlTask {
  id: string // ä»»åŠ¡ID (URL hash)
  url: string // ä¹¦ç­¾URL
  bookmarkId: string // ä¹¦ç­¾ID
  bookmarkTitle: string // ä¹¦ç­¾æ ‡é¢˜
  priority: number // ä¼˜å…ˆçº§ (0-100)
  status: 'pending' | 'running' | 'success' | 'failed' | 'paused'
  retryCount: number // é‡è¯•æ¬¡æ•°
  createdAt: number // åˆ›å»ºæ—¶é—´
  startedAt?: number // å¼€å§‹æ—¶é—´
  finishedAt?: number // å®Œæˆæ—¶é—´
  result?: CrawlResult // çˆ¬å–ç»“æœ
  error?: string // é”™è¯¯ä¿¡æ¯
}

export interface QueueStatistics {
  total: number // æ€»ä»»åŠ¡æ•°
  completed: number // å·²å®Œæˆ
  failed: number // å·²å¤±è´¥
  pending: number // å¾…å¤„ç†
  running: number // è¿è¡Œä¸­
  paused: number // å·²æš‚åœ
  progress: number // è¿›åº¦ç™¾åˆ†æ¯” (0-100)
}

export interface CrawlOptions {
  priority?: 'low' | 'normal' | 'high' | 'urgent'
  respectRobots?: boolean
  onProgress?: (progress: QueueStatistics) => void
  onTaskComplete?: (task: CrawlTask) => void
  onComplete?: (stats: QueueStatistics) => void
  onError?: (error: Error) => void
}

// ==================== å¹¶å‘æ§åˆ¶å™¨ ====================

class ConcurrencyController {
  private readonly MAX_GLOBAL_CONCURRENT: number
  private readonly MAX_PER_DOMAIN_CONCURRENT: number
  private readonly MIN_DOMAIN_INTERVAL_MS: number

  private runningCount = 0
  private domainRunning = new Map<string, number>()
  private domainLastAccess = new Map<string, number>()

  constructor() {
    this.MAX_GLOBAL_CONCURRENT = CRAWLER_CONFIG.CONCURRENCY || 2
    this.MAX_PER_DOMAIN_CONCURRENT = CRAWLER_CONFIG.PER_DOMAIN_CONCURRENCY || 1
    this.MIN_DOMAIN_INTERVAL_MS = 1000
  }

  canStartTask(url: string): boolean {
    try {
      const domain = new URL(url).hostname

      // æ£€æŸ¥å…¨å±€å¹¶å‘
      if (this.runningCount >= this.MAX_GLOBAL_CONCURRENT) {
        return false
      }

      // æ£€æŸ¥åŸŸåå¹¶å‘
      const domainCount = this.domainRunning.get(domain) || 0
      if (domainCount >= this.MAX_PER_DOMAIN_CONCURRENT) {
        return false
      }

      // æ£€æŸ¥åŸŸåé—´éš”
      const lastAccess = this.domainLastAccess.get(domain) || 0
      if (Date.now() - lastAccess < this.MIN_DOMAIN_INTERVAL_MS) {
        return false
      }

      return true
    } catch {
      return false
    }
  }

  async waitForSlot(url: string): Promise<void> {
    return new Promise(resolve => {
      const checkInterval = setInterval(() => {
        if (this.canStartTask(url)) {
          clearInterval(checkInterval)
          resolve()
        }
      }, 100)
    })
  }

  startTask(url: string): void {
    try {
      const domain = new URL(url).hostname
      this.runningCount++
      this.domainRunning.set(domain, (this.domainRunning.get(domain) || 0) + 1)
      this.domainLastAccess.set(domain, Date.now())
    } catch (error) {
      logger.error('ConcurrencyController', 'Failed to start task', error)
    }
  }

  finishTask(url: string): void {
    try {
      const domain = new URL(url).hostname
      this.runningCount = Math.max(0, this.runningCount - 1)
      this.domainRunning.set(
        domain,
        Math.max(0, (this.domainRunning.get(domain) || 1) - 1)
      )
    } catch (error) {
      logger.error('ConcurrencyController', 'Failed to finish task', error)
    }
  }

  getStats() {
    return {
      runningCount: this.runningCount,
      domainsActive: this.domainRunning.size
    }
  }
}

// ==================== ç©ºé—²è°ƒåº¦å™¨ ====================

class IdleScheduler {
  private isUserActive = false
  private lastActivity = Date.now()
  private readonly USER_IDLE_THRESHOLD: number

  constructor() {
    this.USER_IDLE_THRESHOLD = CRAWLER_CONFIG.IDLE_DELAY_MS || 3000
    this.setupActivityDetection()
    this.setupVisibilityDetection()
  }

  private setupActivityDetection() {
    // Service Worker ç¯å¢ƒæ£€æµ‹
    if (typeof document === 'undefined' || typeof window === 'undefined') {
      logger.debug('CrawlScheduler', 'Service Worker ç¯å¢ƒï¼Œè·³è¿‡ç”¨æˆ·æ´»åŠ¨æ£€æµ‹')
      this.isUserActive = false // Service Worker ä¸­è®¤ä¸ºç”¨æˆ·ä¸æ´»è·ƒ
      return
    }

    const events = ['mousedown', 'mousemove', 'keydown', 'scroll', 'touchstart']

    const onActivity = () => {
      this.isUserActive = true
      this.lastActivity = Date.now()
    }

    events.forEach(event => {
      if (document && document.addEventListener) {
        document.addEventListener(event, onActivity, { passive: true })
      }
    })

    // å®šæœŸæ£€æŸ¥ç”¨æˆ·æ˜¯å¦ç©ºé—²
    if (typeof setInterval !== 'undefined') {
      setInterval(() => {
        if (Date.now() - this.lastActivity > this.USER_IDLE_THRESHOLD) {
          this.isUserActive = false
        }
      }, 5000)
    }
  }

  private setupVisibilityDetection() {
    if (typeof document === 'undefined' || typeof window === 'undefined') return

    if (document && document.addEventListener) {
      document.addEventListener('visibilitychange', () => {
        if (document.hidden) {
          this.isUserActive = false
        }
      })
    }
  }

  shouldContinueCrawling(): boolean {
    // å¦‚æœç¦ç”¨äº†ç©ºé—²è°ƒåº¦ï¼Œæ€»æ˜¯è¿”å› true
    if (!CRAWLER_CONFIG.USE_IDLE_SCHEDULING) {
      return true
    }

    // ç”¨æˆ·æ´»è·ƒæ—¶æš‚åœ
    if (this.isUserActive) return false

    // é¡µé¢éšè—æ—¶å¯ä»¥ç»§ç»­
    if (typeof document !== 'undefined' && document && document.hidden) {
      return true
    }

    // ç”¨æˆ·ç©ºé—²è¶³å¤Ÿä¹…æ—¶å¯ä»¥ç»§ç»­
    return Date.now() - this.lastActivity > this.USER_IDLE_THRESHOLD
  }

  async waitForIdleOrTimeout(timeout = 5000): Promise<void> {
    if (!CRAWLER_CONFIG.USE_IDLE_SCHEDULING) {
      return
    }

    const startTime = Date.now()

    return new Promise(resolve => {
      const checkInterval = setInterval(() => {
        if (this.shouldContinueCrawling() || Date.now() - startTime > timeout) {
          clearInterval(checkInterval)
          resolve()
        }
      }, 500)
    })
  }
}

// ==================== æŒä¹…åŒ–é˜Ÿåˆ— ====================

class PersistentQueue {
  private readonly STORAGE_KEY = 'crawl_queue_state_v2'

  async saveState(
    tasks: CrawlTask[],
    statistics: QueueStatistics
  ): Promise<void> {
    if (!chrome?.storage?.local) {
      logger.warn(
        'PersistentQueue',
        'chrome.storage.local ä¸å¯ç”¨ï¼Œè·³è¿‡é˜Ÿåˆ—çŠ¶æ€ä¿å­˜'
      )
      return
    }
    try {
      await chrome.storage.local.set({
        [this.STORAGE_KEY]: {
          tasks: tasks.map(t => ({
            ...t,
            // ä¸ä¿å­˜è¿è¡Œä¸­çŠ¶æ€ï¼Œé‡å¯åé‡æ–°å¼€å§‹
            status: t.status === 'running' ? 'pending' : t.status
          })),
          statistics,
          timestamp: Date.now()
        }
      })
    } catch (error) {
      logger.error('PersistentQueue', 'Failed to save state', error)
    }
  }

  async loadState(): Promise<{
    tasks: CrawlTask[]
    statistics: QueueStatistics
  } | null> {
    if (!chrome?.storage?.local) {
      logger.warn(
        'PersistentQueue',
        'chrome.storage.local ä¸å¯ç”¨ï¼Œè·³è¿‡é˜Ÿåˆ—çŠ¶æ€æ¢å¤'
      )
      return null
    }
    try {
      const result = await chrome.storage.local.get(this.STORAGE_KEY)
      const saved = result[this.STORAGE_KEY]

      if (!saved) return null

      // æ£€æŸ¥çŠ¶æ€æ˜¯å¦å¤ªæ—§ï¼ˆè¶…è¿‡7å¤©ï¼‰
      if (Date.now() - saved.timestamp > 7 * 24 * 60 * 60 * 1000) {
        await this.clearState()
        return null
      }

      return {
        tasks: saved.tasks || [],
        statistics: saved.statistics || this.getDefaultStatistics()
      }
    } catch (error) {
      logger.error('PersistentQueue', 'Failed to load state', error)
      return null
    }
  }

  async clearState(): Promise<void> {
    if (!chrome?.storage?.local) {
      logger.warn(
        'PersistentQueue',
        'chrome.storage.local ä¸å¯ç”¨ï¼Œè·³è¿‡çŠ¶æ€æ¸…é™¤'
      )
      return
    }
    try {
      await chrome.storage.local.remove(this.STORAGE_KEY)
    } catch (error) {
      logger.error('PersistentQueue', 'Failed to clear state', error)
    }
  }

  private getDefaultStatistics(): QueueStatistics {
    return {
      total: 0,
      completed: 0,
      failed: 0,
      pending: 0,
      running: 0,
      paused: 0,
      progress: 0
    }
  }
}

// ==================== ä»»åŠ¡è°ƒåº¦å™¨ä¸»ç±» ====================

export class CrawlTaskScheduler {
  private tasks: CrawlTask[] = []
  private runningTasks = new Map<string, CrawlTask>()
  private statistics: QueueStatistics = {
    total: 0,
    completed: 0,
    failed: 0,
    pending: 0,
    running: 0,
    paused: 0,
    progress: 0
  }

  private concurrencyController = new ConcurrencyController()
  private idleScheduler = new IdleScheduler()
  private persistentQueue = new PersistentQueue()

  private isRunning = false
  private isPaused = false
  private currentOptions: CrawlOptions | null = null

  constructor() {
    this.restoreState()
  }

  // ==================== å…¬å…± API ====================

  /**
   * è°ƒåº¦ä¹¦ç­¾æ‰¹é‡çˆ¬å–
   */
  async scheduleBookmarksCrawl(
    bookmarks: chrome.bookmarks.BookmarkTreeNode[],
    options: CrawlOptions = {}
  ): Promise<string> {
    const taskId = this.generateTaskId()
    this.currentOptions = options

    logger.info('CrawlScheduler', `ğŸ“‹ è°ƒåº¦çˆ¬å–ä»»åŠ¡: ${bookmarks.length} ä¸ªä¹¦ç­¾`)

    // 1. URL å»é‡
    const urlGroups = this.groupBookmarksByURL(bookmarks)
    logger.info(
      'CrawlScheduler',
      `ğŸ”— URLå»é‡: ${bookmarks.length} â†’ ${urlGroups.size} ä¸ªå”¯ä¸€URL`
    )

    // 2. åˆ›å»ºä»»åŠ¡
    const newTasks: CrawlTask[] = []
    const priorityMap = this.getPriorityMap(options.priority)

    for (const [url, group] of urlGroups.entries()) {
      // ä½¿ç”¨ä¼˜å…ˆçº§æœ€é«˜çš„ä¹¦ç­¾ä½œä¸ºä»£è¡¨
      const representative = this.selectRepresentative(group)

      const task: CrawlTask = {
        id: this.hashURL(url),
        url,
        bookmarkId: representative.id,
        bookmarkTitle: representative.title || '',
        priority: this.calculatePriority(representative, priorityMap),
        status: 'pending',
        retryCount: 0,
        createdAt: Date.now()
      }

      newTasks.push(task)
    }

    // 3. æŒ‰ä¼˜å…ˆçº§æ’åº
    newTasks.sort((a, b) => b.priority - a.priority)

    // 4. æ·»åŠ åˆ°é˜Ÿåˆ—
    this.tasks.push(...newTasks)
    this.updateStatistics()

    // 5. æŒä¹…åŒ–
    await this.saveState()

    // 6. å¯åŠ¨æ‰§è¡Œ
    if (!this.isRunning) {
      this.startExecution()
    }

    return taskId
  }

  /**
   * æš‚åœçˆ¬å–
   */
  pause(): void {
    this.isPaused = true
    logger.info('CrawlScheduler', 'â¸ï¸ çˆ¬å–å·²æš‚åœ')
  }

  /**
   * ç»§ç»­çˆ¬å–
   */
  resume(): void {
    this.isPaused = false
    logger.info('CrawlScheduler', 'â–¶ï¸ çˆ¬å–å·²ç»§ç»­')

    if (!this.isRunning) {
      this.startExecution()
    }
  }

  /**
   * å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
   */
  async cancelAll(): Promise<void> {
    this.isPaused = true
    this.isRunning = false
    this.tasks = []
    this.runningTasks.clear()
    this.updateStatistics()
    await this.persistentQueue.clearState()

    logger.info('CrawlScheduler', 'âŒ æ‰€æœ‰ä»»åŠ¡å·²å–æ¶ˆ')
  }

  /**
   * è·å–ç»Ÿè®¡ä¿¡æ¯
   */
  getStatistics(): QueueStatistics {
    return { ...this.statistics }
  }

  /**
   * è·å–æ‰€æœ‰ä»»åŠ¡
   */
  getTasks(): CrawlTask[] {
    return [...this.tasks]
  }

  // ==================== ç§æœ‰æ–¹æ³• ====================

  private async startExecution(): Promise<void> {
    if (this.isRunning) return

    this.isRunning = true
    logger.info('CrawlScheduler', 'ğŸš€ å¼€å§‹æ‰§è¡Œçˆ¬å–ä»»åŠ¡')

    while (this.isRunning && !this.isPaused) {
      // 1. æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†ä»»åŠ¡
      const pendingTasks = this.tasks.filter(t => t.status === 'pending')
      if (pendingTasks.length === 0) {
        break
      }

      // 2. ç­‰å¾…ç©ºé—²æ—¶æ®µ
      if (CRAWLER_CONFIG.USE_IDLE_SCHEDULING) {
        await this.idleScheduler.waitForIdleOrTimeout(5000)
      }

      // 3. æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­
      if (!this.idleScheduler.shouldContinueCrawling()) {
        await new Promise(resolve => setTimeout(resolve, 1000))
        continue
      }

      // 4. è·å–ä¸‹ä¸€ä¸ªå¯æ‰§è¡Œçš„ä»»åŠ¡
      const nextTask = pendingTasks.find(t =>
        this.concurrencyController.canStartTask(t.url)
      )

      if (!nextTask) {
        // ç­‰å¾…æœ‰ä»»åŠ¡å®Œæˆ
        await new Promise(resolve => setTimeout(resolve, 500))
        continue
      }

      // 5. æ‰§è¡Œä»»åŠ¡
      this.executeTask(nextTask)

      // 6. æ‰¹æ¬¡é—´å»¶è¿Ÿ
      await new Promise(resolve =>
        setTimeout(resolve, CRAWLER_CONFIG.BATCH_INTERVAL_MS || 1500)
      )
    }

    this.isRunning = false

    // 7. å®Œæˆå›è°ƒ
    if (this.statistics.pending === 0 && this.statistics.running === 0) {
      logger.info('CrawlScheduler', 'âœ… æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ', this.statistics)
      this.currentOptions?.onComplete?.(this.statistics)
    }
  }

  private async executeTask(task: CrawlTask): Promise<void> {
    // 1. æ›´æ–°çŠ¶æ€
    task.status = 'running'
    task.startedAt = Date.now()
    this.runningTasks.set(task.id, task)
    this.concurrencyController.startTask(task.url)
    this.updateStatistics()

    logger.info('CrawlScheduler', `ğŸ” å¼€å§‹çˆ¬å–: ${task.url}`)

    try {
      // 2. æ‰§è¡Œçˆ¬å–
      const result = await crawlBookmarkLocally(task.url, {
        respectRobots: this.currentOptions?.respectRobots ?? true,
        timeout: 10000
      })

      task.result = result
      task.finishedAt = Date.now()

      // 3. å¤„ç†ç»“æœ
      if (result.success) {
        task.status = 'success'
        logger.info(
          'CrawlScheduler',
          `âœ… çˆ¬å–æˆåŠŸ: ${task.url} (${result.duration}ms)`
        )

        // é€šçŸ¥ä»»åŠ¡å®Œæˆ
        this.currentOptions?.onTaskComplete?.(task)
      } else {
        // é‡è¯•é€»è¾‘
        if (task.retryCount < 2 && this.shouldRetry(result)) {
          task.retryCount++
          task.status = 'pending'
          logger.warn(
            'CrawlScheduler',
            `ğŸ”„ é‡è¯•ä»»åŠ¡ (${task.retryCount}/2): ${task.url}`
          )
        } else {
          task.status = 'failed'
          task.error = result.error
          logger.error(
            'CrawlScheduler',
            `âŒ çˆ¬å–å¤±è´¥: ${task.url}`,
            result.error
          )
        }
      }
    } catch (error) {
      task.status = 'failed'
      task.error = String(error)
      task.finishedAt = Date.now()
      logger.error('CrawlScheduler', `âŒ ä»»åŠ¡å¼‚å¸¸: ${task.url}`, error)
    } finally {
      // 4. æ¸…ç†
      this.runningTasks.delete(task.id)
      this.concurrencyController.finishTask(task.url)
      this.updateStatistics()

      // 5. æŒä¹…åŒ–
      await this.saveState()

      // 6. é€šçŸ¥è¿›åº¦
      this.currentOptions?.onProgress?.(this.statistics)
    }
  }

  private shouldRetry(result: CrawlResult): boolean {
    return result.errorType === 'timeout' || result.errorType === 'network'
  }

  private groupBookmarksByURL(
    bookmarks: chrome.bookmarks.BookmarkTreeNode[]
  ): Map<string, chrome.bookmarks.BookmarkTreeNode[]> {
    const groups = new Map<string, chrome.bookmarks.BookmarkTreeNode[]>()

    for (const bookmark of bookmarks) {
      if (!bookmark.url) continue

      const normalizedURL = this.normalizeURL(bookmark.url)

      if (!groups.has(normalizedURL)) {
        groups.set(normalizedURL, [])
      }

      groups.get(normalizedURL)!.push(bookmark)
    }

    return groups
  }

  private normalizeURL(url: string): string {
    try {
      const parsed = new URL(url)
      parsed.hash = ''

      // ç§»é™¤å¸¸è§è¿½è¸ªå‚æ•°
      const trackingParams = [
        'utm_source',
        'utm_medium',
        'utm_campaign',
        'ref',
        'source'
      ]
      trackingParams.forEach(param => parsed.searchParams.delete(param))

      return parsed.toString()
    } catch {
      return url
    }
  }

  private selectRepresentative(
    bookmarks: chrome.bookmarks.BookmarkTreeNode[]
  ): chrome.bookmarks.BookmarkTreeNode {
    // ä¼˜å…ˆé€‰æ‹©æœ€è¿‘è®¿é—®çš„
    const sorted = bookmarks.sort((a, b) => {
      const aTime = a.dateLastUsed || a.dateAdded || 0
      const bTime = b.dateLastUsed || b.dateAdded || 0
      return bTime - aTime
    })

    return sorted[0]
  }

  private calculatePriority(
    bookmark: chrome.bookmarks.BookmarkTreeNode,
    baseScore: number
  ): number {
    let priority = baseScore

    // æœ€è¿‘æ·»åŠ ä¼˜å…ˆ
    if (bookmark.dateAdded) {
      const daysSinceAdded =
        (Date.now() - bookmark.dateAdded) / (1000 * 60 * 60 * 24)
      if (daysSinceAdded < 7) priority += 20
      else if (daysSinceAdded < 30) priority += 10
    }

    // æœ€è¿‘è®¿é—®ä¼˜å…ˆ
    if (bookmark.dateLastUsed) {
      const daysSinceUsed =
        (Date.now() - bookmark.dateLastUsed) / (1000 * 60 * 60 * 24)
      if (daysSinceUsed < 1) priority += 20
      else if (daysSinceUsed < 7) priority += 10
    }

    return Math.min(100, Math.max(0, priority))
  }

  private getPriorityMap(level?: string): number {
    switch (level) {
      case 'urgent':
        return 90
      case 'high':
        return 70
      case 'normal':
        return 50
      case 'low':
        return 30
      default:
        return 50
    }
  }

  private updateStatistics(): void {
    this.statistics.total = this.tasks.length
    this.statistics.completed = this.tasks.filter(
      t => t.status === 'success'
    ).length
    this.statistics.failed = this.tasks.filter(
      t => t.status === 'failed'
    ).length
    this.statistics.pending = this.tasks.filter(
      t => t.status === 'pending'
    ).length
    this.statistics.running = this.runningTasks.size
    this.statistics.paused = this.tasks.filter(
      t => t.status === 'paused'
    ).length

    const finished = this.statistics.completed + this.statistics.failed
    this.statistics.progress =
      this.statistics.total > 0
        ? Math.round((finished / this.statistics.total) * 100)
        : 0
  }

  private async saveState(): Promise<void> {
    await this.persistentQueue.saveState(this.tasks, this.statistics)
  }

  private async restoreState(): Promise<void> {
    const saved = await this.persistentQueue.loadState()

    if (saved) {
      this.tasks = saved.tasks
      this.statistics = saved.statistics
      logger.info('CrawlScheduler', 'ğŸ“‚ æ¢å¤é˜Ÿåˆ—çŠ¶æ€', this.statistics)

      // å¦‚æœæœ‰æœªå®Œæˆä»»åŠ¡ï¼Œè¯¢é—®æ˜¯å¦ç»§ç»­
      if (this.statistics.pending > 0) {
        // TODO: æ˜¾ç¤ºé€šçŸ¥ï¼Œè®©ç”¨æˆ·é€‰æ‹©æ˜¯å¦ç»§ç»­
      }
    }
  }

  private hashURL(url: string): string {
    // ç®€å•çš„å“ˆå¸Œå‡½æ•°
    let hash = 0
    for (let i = 0; i < url.length; i++) {
      const char = url.charCodeAt(i)
      hash = (hash << 5) - hash + char
      hash = hash & hash
    }
    return Math.abs(hash).toString(36)
  }

  private generateTaskId(): string {
    return `task_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`
  }
}

// ==================== å¯¼å‡ºå•ä¾‹ ====================

export const crawlTaskScheduler = new CrawlTaskScheduler()
