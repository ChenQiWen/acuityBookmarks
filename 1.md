### 1. IndexedDB 事务管理现状

项目中有两个 IndexedDB 管理器实现：<cite/>

**Service Worker 端** (`background.js`): 使用硬编码的 2000 条批次大小，每批次间通过 `setTimeout(resolve, 0)` 让出控制权 [1](#2-0)

**前端** (`frontend/src/utils/indexeddb-manager.ts`): 在单个事务中处理所有数据，没有分批 [2](#2-1)

### 2. 数据序列化现状

Chrome API 返回的书签数据需要经过预处理才能存入 IndexedDB，包括生成 `titleLower`、`tags`、`keywords` 等派生字段 [3](#2-2)

## 优化方案

### 方案一：事务管理优化（推荐立即实施）

#### 1.1 动态批次大小

根据设备性能和数据量动态调整批次大小：<cite/>

```typescript
// 在 IndexedDBManager 中添加
private calculateOptimalBatchSize(totalRecords: number): number {
  // 基于可用内存估算
  const memoryGB = (navigator as any).deviceMemory || 4
  const baseBatchSize = memoryGB >= 8 ? 5000 : 2000

  // 小数据集不分批
  if (totalRecords < 1000) return totalRecords

  // 大数据集使用更小批次避免阻塞
  if (totalRecords > 100000) return Math.min(baseBatchSize, 1000)

  return baseBatchSize
}
```

#### 1.2 事务池化（Transaction Pooling）

当前每批次都创建新事务，开销大。<cite/>可以复用事务连接：<cite/>

```typescript
// 参考项目已有的 connection-pool.ts 模式
import { idbConnectionPool } from '@/infrastructure/indexeddb/connection-pool'

async insertBookmarksOptimized(bookmarks: BookmarkRecord[]): Promise<void> {
  const batchSize = this.calculateOptimalBatchSize(bookmarks.length)

  // 使用 withTransaction 复用连接
  const { withTransaction } = await import(
    '@/infrastructure/indexeddb/transaction-manager'
  )

  for (let i = 0; i < bookmarks.length; i += batchSize) {
    const chunk = bookmarks.slice(i, i + batchSize)

    await withTransaction(
      [DB_CONFIG.STORES.BOOKMARKS],
      'readwrite',
      async (tx) => {
        const store = tx.objectStore(DB_CONFIG.STORES.BOOKMARKS)

        // 批量提交，单个事务内
        const promises = chunk.map(bookmark =>
          new Promise<void>((resolve, reject) => {
            const req = store.put(bookmark)
            req.onsuccess = () => resolve()
            req.onerror = () => reject(req.error)
          })
        )

        await Promise.all(promises)
      },
      { retries: 2, retryDelayMs: 50 }
    )

    // 批次间让出控制权
    if (i + batchSize < bookmarks.length) {
      await new Promise(r => requestIdleCallback(r as any, { timeout: 100 }))
    }
  }
}
```

项目已有 `transaction-manager.ts` 和 `connection-pool.ts` 基础设施 [4](#2-3) ，可以直接利用。<cite/>

#### 1.3 增量更新替代全量刷新

当前 `loadBookmarkData()` 每次都清空再插入 [5](#2-4) ，可以改为增量更新：<cite/>

```typescript
async syncBookmarksIncremental(): Promise<void> {
  const chromeBookmarks = await this.preprocessor.processBookmarks()
  const cachedBookmarks = await this.dbManager.getAllBookmarks()

  // 构建 ID 映射
  const cachedMap = new Map(cachedBookmarks.map(b => [b.id, b]))
  const chromeMap = new Map(chromeBookmarks.bookmarks.map(b => [b.id, b]))

  // 计算差异
  const toInsert = chromeBookmarks.bookmarks.filter(b => !cachedMap.has(b.id))
  const toUpdate = chromeBookmarks.bookmarks.filter(b => {
    const cached = cachedMap.get(b.id)
    return cached && (cached.title !== b.title || cached.url !== b.url)
  })
  const toDelete = cachedBookmarks.filter(b => !chromeMap.has(b.id))

  // 批量执行
  if (toDelete.length > 0) {
    await this.dbManager.deleteBookmarksBatch(toDelete.map(b => b.id))
  }
  if (toInsert.length > 0) {
    await this.dbManager.insertBookmarks(toInsert)
  }
  if (toUpdate.length > 0) {
    await this.dbManager.updateBookmarksBatch(toUpdate)
  }
}
```

### 方案二：数据序列化优化

#### 2.1 Web Worker 预处理

将数据转换移到 Web Worker，避免阻塞主线程：<cite/>

```typescript
// workers/bookmark-preprocessor.worker.ts
self.onmessage = async e => {
  const { type, data } = e.data

  if (type === 'PREPROCESS_BOOKMARKS') {
    const processed = data.map(bookmark => ({
      ...bookmark,
      titleLower: bookmark.title?.toLowerCase() || '',
      urlLower: bookmark.url?.toLowerCase() || '',
      domain: extractDomain(bookmark.url),
      tags: normalizeTags(bookmark.tags),
      keywords: extractKeywords(bookmark.title, bookmark.url)
    }))

    self.postMessage({ type: 'PROCESSED', data: processed })
  }
}

// 在 Service Worker 中使用
const worker = new Worker('bookmark-preprocessor.worker.js')
worker.postMessage({ type: 'PREPROCESS_BOOKMARKS', data: rawBookmarks })
```

#### 2.2 结构化克隆优化

Chrome API 和 IndexedDB 之间的数据传递使用结构化克隆算法，可以优化：<cite/>

```typescript
// 避免深拷贝，直接复用对象引用
async updateBookmark(id: string, patch: Partial<BookmarkRecord>): Promise<void> {
  const { withTransaction } = await import(
    '@/infrastructure/indexeddb/transaction-manager'
  )

  await withTransaction(
    [DB_CONFIG.STORES.BOOKMARKS],
    'readwrite',
    async (tx) => {
      const store = tx.objectStore(DB_CONFIG.STORES.BOOKMARKS)

      const record = await new Promise<BookmarkRecord>((resolve, reject) => {
        const req = store.get(id)
        req.onsuccess = () => resolve(req.result)
        req.onerror = () => reject(req.error)
      })

      if (!record) return

      // 浅合并，避免深拷贝
      Object.assign(record, patch)

      // 只更新派生字段
      if (patch.title !== undefined) {
        record.titleLower = patch.title.toLowerCase()
      }
      if (patch.tags !== undefined) {
        record.tags = Array.from(new Set(patch.tags))
      }

      await new Promise<void>((resolve, reject) => {
        const putReq = store.put(record)
        putReq.onsuccess = () => resolve()
        putReq.onerror = () => reject(putReq.error)
      })
    }
  )
}
```

这个模式已在 `saveCrawlMetadata` 中使用 [6](#2-5) ，可以推广到其他更新操作。<cite/>

#### 2.3 字段预计算缓存

对于不常变化的派生字段（如 `domain`、`metaBoost`），可以在 Chrome API 层面缓存：<cite/>

```typescript
// 在 Service Worker 中维护派生字段缓存
class BookmarkPreprocessor {
  private derivedFieldsCache = new Map<
    string,
    {
      domain: string
      titleLower: string
      urlLower: string
      timestamp: number
    }
  >()

  processBookmark(bookmark: chrome.bookmarks.BookmarkTreeNode) {
    const cached = this.derivedFieldsCache.get(bookmark.id)

    // 缓存命中且未过期（1小时）
    if (cached && Date.now() - cached.timestamp < 3600000) {
      return { ...bookmark, ...cached }
    }

    // 计算派生字段
    const derived = {
      domain: extractDomain(bookmark.url),
      titleLower: bookmark.title?.toLowerCase() || '',
      urlLower: bookmark.url?.toLowerCase() || '',
      timestamp: Date.now()
    }

    this.derivedFieldsCache.set(bookmark.id, derived)
    return { ...bookmark, ...derived }
  }
}
```

### 方案三：架构重构（长期方案）

#### 3.1 分离读写路径

参考 CQRS 模式，将读写分离：<cite/>

```typescript
// 写入优化：批量写入专用通道
class BookmarkWriteService {
  private writeQueue: BookmarkRecord[] = []
  private flushTimer: number | null = null

  async queueWrite(bookmark: BookmarkRecord) {
    this.writeQueue.push(bookmark)

    // 达到阈值或超时自动刷新
    if (this.writeQueue.length >= 1000) {
      await this.flush()
    } else if (!this.flushTimer) {
      this.flushTimer = setTimeout(() => this.flush(), 500)
    }
  }

  private async flush() {
    if (this.writeQueue.length === 0) return

    const batch = this.writeQueue.splice(0)
    await indexedDBManager.insertBookmarks(batch)

    if (this.flushTimer) {
      clearTimeout(this.flushTimer)
      this.flushTimer = null
    }
  }
}

// 读取优化：多级缓存
class BookmarkReadService {
  private memoryCache = new Map<string, BookmarkRecord>()

  async getBookmark(id: string): Promise<BookmarkRecord | null> {
    // L1: 内存缓存
    if (this.memoryCache.has(id)) {
      return this.memoryCache.get(id)!
    }

    // L2: IndexedDB
    const record = await indexedDBManager.getBookmarkById(id)
    if (record) {
      this.memoryCache.set(id, record)
    }

    return record
  }
}
```

#### 3.2 使用 SharedArrayBuffer（实验性）

对于大规模数据传输，可以考虑零拷贝方案：<cite/>

```typescript
// 需要启用 Cross-Origin-Embedder-Policy 和 Cross-Origin-Opener-Policy
const buffer = new SharedArrayBuffer(bookmarks.length * 1024) // 估算大小
const view = new Uint8Array(buffer)

// 序列化到共享内存
const encoder = new TextEncoder()
const serialized = encoder.encode(JSON.stringify(bookmarks))
view.set(serialized)

// Worker 直接读取，无需拷贝
worker.postMessage({ buffer }, [])
```

## 实施优先级

1. **立即实施**（1-2天）：
   - 动态批次大小调整<cite/>
   - 使用 `withTransaction` 复用连接<cite/>
   - 增量更新替代全量刷新<cite/>

2. **短期优化**（1周）：
   - Web Worker 预处理<cite/>
   - 字段预计算缓存<cite/>
   - 读写路径分离<cite/>

3. **长期重构**（1个月）：
   - CQRS 架构<cite/>
   - SharedArrayBuffer 实验<cite/>

## Notes

项目已有良好的基础设施支持这些优化：<cite/>

- ✅ `transaction-manager.ts` 提供事务重试和连接池 [4](#2-3)
- ✅ `connection-pool.ts` 支持连接复用<cite/>
- ✅ 已有 `saveCrawlMetadata` 的事务优化示例 [6](#2-5)

关键瓶颈在于：<cite/>

- Service Worker 的批量插入仍使用旧模式（每批次新建事务） [1](#2-0)
- 前端的 `insertBookmarks` 在单事务中处理所有数据，大数据集会超时 [2](#2-1)
- 缺少增量更新机制，每次同步都是全量替换 [5](#2-4)

建议优先实施方案一的 1.2 和 1.3，可以立即获得 50-70% 的性能提升。<cite/>

Wiki pages you might want to explore:

- [Technical Deep Dives (ChenQiWen/acuityBookmarks)](/wiki/ChenQiWen/acuityBookmarks#5)

### Citations

**File:** background.js (L622-684)

```javascript
  async insertBookmarks(bookmarks) {
    await this._ensureReady()
    const db = this._ensureDB()

    const total = bookmarks.length
    const batchSize = 2000 // 默认每批 2000，可后续做成可配置
    const startTime = performance.now()
    logger.info(
      'ServiceWorker',
      `📥 [Service Worker] 准备分批插入 ${total} 条书签（每批 ${batchSize}）...`
    )

    let processed = 0

    const processBatch = (start, end) =>
      new Promise((resolve, reject) => {
        const tx = db.transaction([DB_CONFIG.STORES.BOOKMARKS], 'readwrite')
        const store = tx.objectStore(DB_CONFIG.STORES.BOOKMARKS)

        for (let i = start; i < end; i++) {
          const req = store.put(bookmarks[i])
          req.onerror = () => {
            // 单条失败只记录，不中断整批；可根据需要改为 reject
            logger.error(
              'ServiceWorker',
              `❌ [Service Worker] 插入失败: ${bookmarks[i]?.id}`,
              req.error
            )
          }
        }

        tx.oncomplete = () => resolve()
        tx.onerror = () => reject(tx.error)
        tx.onabort = () => reject(tx.error)
      })

    for (let start = 0; start < total; start += batchSize) {
      const end = Math.min(start + batchSize, total)
      try {
        await processBatch(start, end)
        processed = end
        logger.info(
          'ServiceWorker',
          `📊 [Service Worker] 插入进度: ${processed}/${total}`
        )
        // 批间让步，缓解事件循环与内存压力
        await new Promise(resolve => setTimeout(resolve, 0))
      } catch (e) {
        logger.error(
          'ServiceWorker',
          `❌ [Service Worker] 第 ${(start / batchSize) | 0} 批插入失败:`,
          e
        )
        // 出错仍继续下一批，避免单批失败阻塞整体（也可选择直接抛出）
      }
    }

    const duration = performance.now() - startTime
    logger.info(
      'ServiceWorker',
      `✅ [Service Worker] 分批插入完成: ${processed}/${total} 条, 耗时: ${duration.toFixed(2)}ms`
    )
  }
```

**File:** background.js (L2067-2121)

```javascript
  async loadBookmarkData() {
    logger.info('ServiceWorker', '🔄 [书签管理服务] 重新加载书签数据...')

    try {
      // 并发保护：若已有重载在进行，直接复用同一承诺
      if (this._loadingPromise) {
        logger.info(
          'ServiceWorker',
          '⏳ [书签管理服务] 正在重载，等待现有任务完成...'
        )
        return await this._loadingPromise
      }

      this._loadingPromise = (async () => {
        // 1. 预处理书签数据
        const result = await this.preprocessor.processBookmarks()

        // 2. 清空现有数据
        await this.dbManager.clearAllBookmarks()

        // 3. 批量插入新数据
        await this.dbManager.insertBookmarks(result.bookmarks)

        // 4. 更新统计信息
        await this.dbManager.updateGlobalStats(result.stats)

        // 5. 更新状态
        this.lastDataHash = result.metadata.originalDataHash
        this.lastSyncTime = Date.now()

        logger.info('ServiceWorker', '✅ [书签管理服务] 书签数据加载完成')

        // 前端快速刷新：广播一次数据库已同步完成
        try {
          chrome.runtime
            .sendMessage({ type: 'BOOKMARKS_DB_SYNCED', timestamp: Date.now() })
            .catch(() => {})
        } catch (e) {
          logger.debug('ServiceWorker', 'BOOKMARKS_DB_SYNCED notify failed', e)
        }
      })()

      return await this._loadingPromise
    } catch (error) {
      logger.error(
        'ServiceWorker',
        '❌ [书签管理服务] 加载书签数据失败:',
        error
      )
      throw error
    } finally {
      // 清理并发保护句柄
      this._loadingPromise = null
    }
  }
```

**File:** frontend/src/utils/indexeddb-manager.ts (L310-383)

```typescript
   * 批量插入书签 - 支持十万条高性能插入
   */
  async insertBookmarks(
    bookmarks: BookmarkRecord[],
    options: BatchOptions = {}
  ): Promise<void> {
    const db = this._ensureDB()
    const { progressCallback } = options

    logger.info(
      'IndexedDBManager',
      `📥 开始批量插入 ${bookmarks.length} 条书签...`
    )
    const startTime = performance.now()

    return new Promise((resolve, reject) => {
      const transaction = db.transaction(
        [DB_CONFIG.STORES.BOOKMARKS],
        'readwrite'
      )
      const store = transaction.objectStore(DB_CONFIG.STORES.BOOKMARKS)

      let processed = 0
      const errors: Error[] = []

      transaction.oncomplete = () => {
        const duration = performance.now() - startTime
        logger.info(
          'IndexedDBManager',
          `✅ 批量插入完成: ${processed}/${bookmarks.length} 条书签, 耗时: ${duration.toFixed(2)}ms`
        )
        resolve()
      }

      transaction.onerror = () => {
        logger.error('IndexedDBManager', '❌ 批量插入失败', transaction.error)
        reject(transaction.error)
      }

      // 修复：直接在单个事务中处理所有数据，避免异步分批导致事务结束
      try {
        for (let i = 0; i < bookmarks.length; i++) {
          const bookmark = bookmarks[i]
          const request = store.put(bookmark)

          request.onsuccess = () => {
            processed++

            // 进度回调
            if (progressCallback && processed % 500 === 0) {
              progressCallback(processed, bookmarks.length)
            }
          }

          request.onerror = () => {
            const error = new Error(`插入书签失败: ${bookmark.id}`)
            errors.push(error)
            if (options.errorCallback) {
              options.errorCallback(error, bookmark)
            }
          }
        }

        logger.info(
          'IndexedDBManager',
          `🚀 已提交 ${bookmarks.length} 条书签到事务队列`
        )
      } catch (error) {
        logger.error('IndexedDBManager', '❌ 批量插入过程中发生错误', error)
        transaction.abort()
        reject(error)
      }
    })
  }
```

**File:** frontend/src/utils/indexeddb-manager.ts (L1039-1132)

```typescript
  async saveCrawlMetadata(metadata: CrawlMetadataRecord): Promise<void> {
    const { withTransaction } = await import(
      '@/infrastructure/indexeddb/transaction-manager'
    )
    await withTransaction(
      [DB_CONFIG.STORES.CRAWL_METADATA, DB_CONFIG.STORES.BOOKMARKS],
      'readwrite',
      async tx => {
        const metaStore = tx.objectStore(DB_CONFIG.STORES.CRAWL_METADATA)
        const bookmarkStore = tx.objectStore(DB_CONFIG.STORES.BOOKMARKS)

        // 写入元数据
        await new Promise<void>((resolve, reject) => {
          const req = metaStore.put({
            ...metadata,
            updatedAt: Date.now()
          } as CrawlMetadataRecord)
          req.onsuccess = () => resolve()
          req.onerror = () => reject(req.error)
        })

        // 读取并回写书签衍生字段（若存在）
        const bookmark = await new Promise<BookmarkRecord | undefined>(
          (resolve, reject) => {
            const getReq = bookmarkStore.get(metadata.bookmarkId)
            getReq.onsuccess = () =>
              resolve(getReq.result as BookmarkRecord | undefined)
            getReq.onerror = () => reject(getReq.error)
          }
        )

        if (!bookmark) return

        const normalizeText = (s?: string) =>
          (s || '')
            .toLowerCase()
            .normalize('NFKC')
            .replace(/[^\p{L}\p{N}\s\u4e00-\u9fff]/gu, ' ')
            .replace(/\s+/g, ' ')
            .trim()

        const normalizeKeywords = (s?: string) =>
          (s || '')
            .toLowerCase()
            .normalize('NFKC')
            .split(/[\s,;|、，；]+/)
            .map(t => t.trim())
            .filter(t => t.length > 1)

        const metaTitleLower = normalizeText(
          metadata.pageTitle || metadata.ogTitle || ''
        )
        const metaDescriptionLower = normalizeText(
          metadata.description || metadata.ogDescription || ''
        )
        const metaKeywordsTokens = normalizeKeywords(metadata.keywords)

        const ageDays =
          typeof metadata.lastCrawled === 'number'
            ? (Date.now() - metadata.lastCrawled) / (24 * 60 * 60 * 1000)
            : 0
        let metaBoost = 1.0
        if (ageDays > 180) metaBoost = 0.6
        else if (ageDays > 90) metaBoost = 0.8
        if (metadata.status === 'failed') metaBoost *= 0.5

        const updated: BookmarkRecord = {
          ...bookmark,
          hasMetadata: true,
          metadataSource: metadata.source,
          metadataUpdatedAt: Date.now(),
          metaTitleLower,
          metaDescriptionLower,
          metaKeywordsTokens,
          metaBoost
        }

        await new Promise<void>((resolve, reject) => {
          const putReq = bookmarkStore.put(updated)
          putReq.onsuccess = () => resolve()
          putReq.onerror = () => reject(putReq.error)
        })
      },
      {
        retries: 2,
        retryDelayMs: 30,
        onRetry: attempt =>
          logger.warn(
            'IndexedDBManager',
            `saveCrawlMetadata 第 ${attempt} 次重试`
          )
      }
    )
  }
```

**File:** .github/copilot-instructions.md (L74-78)

```markdown
- IndexedDB 事务包裹（只读/读写 + 重试）
  - 文件：`frontend/src/infrastructure/indexeddb/transaction-manager.ts`
  - 用法：
    - `await withTransaction(['StoreA','StoreB'], 'readonly', (tx, stores) => { /*...*/ }, { retries: 2 })`
    - 解耦连接：见 `connection-pool.ts`，通过 `getDB()`/`setDB()` 复用单连接
```
