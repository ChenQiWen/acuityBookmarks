# 本地化爬取 - 总结

## 🎯 你的两个关注点

### 1️⃣ 代码冲突与清理

#### 现状分析

```
现有实现（有问题）:
├── serverless-crawler-client.ts      ❌ 上传数据到服务器
├── lightweight-bookmark-enhancer.ts  ❌ 使用 Serverless
│   ├── 独立 IndexedDB                ❌ AcuityBookmarks_LightweightCache
│   └── 独立数据表                    ❌ bookmark_metadata
└── 数据未关联                        ❌ 与 bookmarks 表分离
```

#### 新架构（完全本地）

```
新实现（完全本地）:
├── local-crawler-worker.ts          ✅ Offscreen Document，100%本地
├── crawl-task-scheduler.ts          ✅ 队列、并发、调度
├── local-bookmark-crawler.ts        ✅ 统一入口，数据保存
└── 统一 IndexedDB: AcuityBookmarksDB
    ├── crawlMetadata 表             ✅ 爬取元数据
    └── bookmarks 表                 ✅ 关联字段（hasMetadata等）
```

#### 需要删除的代码

| 文件/代码                            | 原因             | 操作                                 |
| ------------------------------------ | ---------------- | ------------------------------------ |
| `serverless-crawler-client.ts`       | 上传数据到服务器 | **完全删除**                         |
| `lightweight-bookmark-enhancer.ts`   | 独立 IndexedDB   | **重构简化**                         |
| 独立 IndexedDB 代码                  | 与主库分离       | **删除，统一使用 AcuityBookmarksDB** |
| `serverlessCrawlerClient` 的所有引用 | 旧实现           | **替换为新 API**                     |

#### 清理后的效果

- ✅ **零冗余**：所有 Serverless 代码已删除
- ✅ **零混淆**：只有一套本地爬取逻辑
- ✅ **零冲突**：新旧代码完全分离

---

### 2️⃣ 数据保存与关联

#### 数据流向

```
爬取流程:
  用户触发
    ↓
  crawlSingleBookmark()
    ↓
  crawlBookmarkLocally() ← Offscreen Document
    ↓
  saveCrawlResult()
    ↓
  ├─→ crawlMetadata 表（爬取元数据）
    ↓   bookmarkId: '123'
    ↓   pageTitle: '页面标题'
    ↓   description: '描述'
    ↓   keywords: '关键词'
    ↓   ...
    ↓
  └─→ bookmarks 表（更新关联）
        hasMetadata: true
        metadataUpdatedAt: 1234567890
        metaTitleLower: '页面标题'
        metaBoost: 1.5
```

#### 数据表设计

**表1: `crawlMetadata`** - 存储爬取的元数据

```typescript
interface CrawlMetadataRecord {
  bookmarkId: string // 主键，关联到 bookmarks.id
  url: string // 原始 URL

  // 爬取的元数据
  pageTitle?: string // 网页标题
  description?: string // 描述
  keywords?: string // 关键词
  ogTitle?: string // Open Graph 标题
  ogDescription?: string
  ogImage?: string
  ogSiteName?: string

  // 状态
  source: 'crawler'
  status: 'success' | 'failed'
  httpStatus?: number
  lastCrawled?: number

  // 维护
  updatedAt: number
  version: string
}
```

**表2: `bookmarks`** - 更新关联字段

```typescript
interface BookmarkRecord {
  id: string
  title: string
  url?: string

  // 元数据关联（自动更新）
  hasMetadata?: boolean // ✅ 是否有元数据
  metadataUpdatedAt?: number // ✅ 元数据更新时间
  metadataSource?: 'crawler' // ✅ 来源

  // 派生字段（用于搜索增强）
  metaTitleLower?: string // ✅ 小写标题
  metaDescriptionLower?: string // ✅ 小写描述
  metaKeywordsTokens?: string[] // ✅ 关键词数组
  metaBoost?: number // ✅ 搜索权重
}
```

#### 数据保存逻辑

```typescript
// 在 local-bookmark-crawler.ts 中

export async function saveCrawlResult(
  bookmarkId: string,
  url: string,
  result: CrawlResult
): Promise<void> {
  // 1. 保存到 crawlMetadata 表
  await indexedDBManager.saveCrawlMetadata({
    bookmarkId,
    url,
    pageTitle: result.metadata.title,
    description: result.metadata.description
    // ... 其他字段
  })

  // 2. 更新 bookmarks 表的关联字段
  await indexedDBManager.updateBookmark(bookmarkId, {
    hasMetadata: true,
    metadataUpdatedAt: Date.now(),
    metadataSource: 'crawler',
    metaTitleLower: result.metadata.title.toLowerCase()
    // ... 其他派生字段
  })
}
```

#### 业务使用示例

**示例1: 搜索增强**

```typescript
// 搜索时，元数据会自动参与匹配
const results = await searchBookmarks('关键词')

// 结果会包含：
// - bookmark.title (书签原标题)
// - bookmark.metaTitleLower (网页实际标题)
// - bookmark.metaDescriptionLower (网页描述)
// - bookmark.metaKeywordsTokens (网页关键词)
```

**示例2: 显示元数据**

```typescript
// 获取书签的完整信息
const bookmark = await indexedDBManager.getBookmarkById('123')

if (bookmark.hasMetadata) {
  // 获取爬取的元数据
  const metadata = await indexedDBManager.getCrawlMetadata(bookmark.id)

  console.log('网页标题:', metadata.pageTitle)
  console.log('网页描述:', metadata.description)
  console.log('关键词:', metadata.keywords)
}
```

**示例3: 批量查询**

```typescript
// 批量获取多个书签的元数据
const metadataMap = await indexedDBManager.getBatchCrawlMetadata([
  'id1',
  'id2',
  'id3'
])

metadataMap.forEach((metadata, bookmarkId) => {
  console.log(`${bookmarkId}: ${metadata.pageTitle}`)
})
```

**示例4: 刷新过期数据**

```typescript
// 获取需要刷新的书签
const bookmarks = await getBookmarksNeedingCrawl()

console.log(`需要刷新: ${bookmarks.length} 个书签`)

// 批量刷新
await crawlMultipleBookmarks(bookmarks, {
  skipExisting: false, // 强制刷新
  onProgress: stats => {
    console.log(`进度: ${stats.progress}%`)
  }
})
```

---

## 📊 关键数据关系

### 一对一关系

```
bookmarks (1) ←→ (0..1) crawlMetadata
   id                     bookmarkId

一个书签 → 最多一条爬取元数据
一条爬取元数据 → 对应一个书签
```

### 查询模式

#### 模式1: 从书签查元数据

```typescript
// 1. 查询书签
const bookmark = await indexedDBManager.getBookmarkById('123')

// 2. 检查是否有元数据
if (bookmark.hasMetadata) {
  // 3. 查询元数据
  const metadata = await indexedDBManager.getCrawlMetadata('123')
}
```

#### 模式2: 搜索时自动匹配

```typescript
// 搜索引擎会自动使用派生字段
// 无需手动join，性能更好

const results = await searchBookmarks('React')

// 会匹配：
// - bookmark.titleLower
// - bookmark.metaTitleLower        ← 来自爬取
// - bookmark.metaDescriptionLower  ← 来自爬取
// - bookmark.metaKeywordsTokens    ← 来自爬取
```

#### 模式3: 统计和分析

```typescript
// 获取爬取统计
const stats = await getCrawlStatistics()

console.log({
  总书签数: stats.total,
  已爬取: stats.withMetadata,
  未爬取: stats.withoutMetadata,
  失败: stats.failed,
  过期: stats.expired
})
```

---

## 🔧 IndexedDB Manager 新增方法

在 `frontend/src/utils-legacy/indexeddb-manager.ts` 中添加：

```typescript
// 1. 保存爬取元数据
async saveCrawlMetadata(record: CrawlMetadataRecord): Promise<void>

// 2. 获取爬取元数据
async getCrawlMetadata(bookmarkId: string): Promise<CrawlMetadataRecord | null>

// 3. 批量获取
async getBatchCrawlMetadata(bookmarkIds: string[]): Promise<Map<string, CrawlMetadataRecord>>

// 4. 删除元数据
async deleteCrawlMetadata(bookmarkId: string): Promise<void>
```

---

## ✅ 最终效果

### 代码层面

| 指标     | 旧实现  | 新实现  |
| -------- | ------- | ------- |
| 文件数   | 2个独立 | 3个协作 |
| 数据库   | 2个分离 | 1个统一 |
| 数据上传 | ❌ 是   | ✅ 否   |
| 代码冗余 | ❌ 有   | ✅ 无   |
| 关联清晰 | ❌ 否   | ✅ 是   |

### 数据层面

| 指标       | 旧实现    | 新实现         |
| ---------- | --------- | -------------- |
| 元数据存储 | 独立表    | crawlMetadata  |
| 书签关联   | ❌ 无     | ✅ hasMetadata |
| 搜索增强   | ❌ 无     | ✅ 派生字段    |
| 查询性能   | ⚠️ 需join | ✅ 预计算      |

### 用户体验

| 指标     | 效果              |
| -------- | ----------------- |
| 隐私保护 | ✅ 100%本地       |
| 搜索质量 | ✅ 元数据增强     |
| 性能     | ✅ 1000书签<3分钟 |
| 数据一致 | ✅ 自动同步       |

---

## 🚀 快速开始

### 第一步：添加 IndexedDB 方法

```bash
# 编辑文件
code frontend/src/utils-legacy/indexeddb-manager.ts

# 添加四个新方法（见上文）
```

### 第二步：重构 lightweight-bookmark-enhancer.ts

```bash
# 编辑文件
code frontend/src/services/lightweight-bookmark-enhancer.ts

# 替换为简化版（见实施步骤文档）
```

### 第三步：删除 Serverless Crawler

```bash
rm frontend/src/services/serverless-crawler-client.ts
```

### 第四步：测试

```bash
cd frontend
npm run build
npm run test
```

---

## 📚 相关文档

1. [本地化爬取架构方案](./本地化爬取架构方案.md) - 完整架构设计
2. [本地化爬取集成指南](./本地化爬取集成指南.md) - 使用示例
3. [本地化爬取清理集成方案](./本地化爬取-清理集成方案.md) - 清理计划
4. [本地化爬取实施步骤](./本地化爬取-实施步骤.md) - 详细步骤

---

## 🎯 核心要点

### ✅ 关于冲突和清理

1. **完全删除** `serverless-crawler-client.ts`
2. **重构简化** `lightweight-bookmark-enhancer.ts`
3. **统一使用** `AcuityBookmarksDB`
4. **零混淆** - 只有一套本地爬取逻辑

### ✅ 关于数据保存和关联

1. **元数据保存** - `crawlMetadata` 表，`bookmarkId` 为主键
2. **自动关联** - `bookmarks.hasMetadata` 等字段自动更新
3. **搜索增强** - 派生字段（metaTitleLower 等）预计算
4. **一对一关系** - 书签 ↔ 爬取元数据

---

**版本**: v1.0  
**创建时间**: 2025-10-12  
**预计工时**: 1.5-2小时  
**状态**: ✅ 可执行
