# 本地化爬取 - 实施步骤

## 🎯 目标

1. ✅ **完全本地化**：移除 Serverless Crawler，100% 客户端执行
2. ✅ **统一数据库**：使用 `AcuityBookmarksDB`，数据保存到 `crawlMetadata` 表
3. ✅ **数据关联**：`bookmarks` 表的 `hasMetadata` 等字段正确关联
4. ✅ **清理冗余**：删除独立 IndexedDB 和无用代码

---

## 📋 实施清单

### 阶段1: 准备工作（5分钟）

#### 1.1 备份代码

```bash
cd /Users/cqw/Documents/github/acuityBookmarks

# 创建备份分支
git checkout -b backup-before-local-crawler
git add .
git commit -m "backup: 本地化爬取重构前的备份"

# 创建工作分支
git checkout -b feature/local-crawler
```

#### 1.2 确认文件清单

**新创建的文件**：

- ✅ `frontend/src/services/crawl-task-scheduler.ts`
- ✅ `frontend/src/services/local-crawler-worker.ts`
- ✅ `frontend/src/services/local-bookmark-crawler.ts`

**需要修改的文件**：

- `frontend/src/services/lightweight-bookmark-enhancer.ts`
- `frontend/src/utils-legacy/indexeddb-manager.ts`
- `frontend/src/config/constants.ts`（环境变量）

**需要删除的文件**：

- `frontend/src/services/serverless-crawler-client.ts`

---

### 阶段2: 添加 IndexedDB 方法（10分钟）

#### 2.1 找到 IndexedDB Manager 文件

```bash
# 实际的 manager 文件
frontend/src/utils-legacy/indexeddb-manager.ts
```

#### 2.2 添加以下方法

在 `IndexedDBManager` 类中添加：

```typescript
/**
 * 保存爬取元数据
 */
async saveCrawlMetadata(record: CrawlMetadataRecord): Promise<void> {
  if (!this.db) {
    throw new Error('Database not initialized')
  }

  return new Promise((resolve, reject) => {
    const transaction = this.db!.transaction(['crawlMetadata'], 'readwrite')
    const store = transaction.objectStore('crawlMetadata')
    const request = store.put(record)

    request.onsuccess = () => {
      logger.debug('IndexedDBManager', `✅ 保存爬取元数据: ${record.bookmarkId}`)
      resolve()
    }
    request.onerror = () => {
      logger.error('IndexedDBManager', '❌ 保存爬取元数据失败', request.error)
      reject(request.error)
    }
  })
}

/**
 * 获取爬取元数据
 */
async getCrawlMetadata(bookmarkId: string): Promise<CrawlMetadataRecord | null> {
  if (!this.db) {
    throw new Error('Database not initialized')
  }

  return new Promise((resolve, reject) => {
    const transaction = this.db!.transaction(['crawlMetadata'], 'readonly')
    const store = transaction.objectStore('crawlMetadata')
    const request = store.get(bookmarkId)

    request.onsuccess = () => resolve(request.result || null)
    request.onerror = () => reject(request.error)
  })
}

/**
 * 批量获取爬取元数据
 */
async getBatchCrawlMetadata(
  bookmarkIds: string[]
): Promise<Map<string, CrawlMetadataRecord>> {
  const result = new Map<string, CrawlMetadataRecord>()

  for (const id of bookmarkIds) {
    const metadata = await this.getCrawlMetadata(id)
    if (metadata) {
      result.set(id, metadata)
    }
  }

  return result
}

/**
 * 删除爬取元数据
 */
async deleteCrawlMetadata(bookmarkId: string): Promise<void> {
  if (!this.db) {
    throw new Error('Database not initialized')
  }

  return new Promise((resolve, reject) => {
    const transaction = this.db!.transaction(['crawlMetadata'], 'readwrite')
    const store = transaction.objectStore('crawlMetadata')
    const request = store.delete(bookmarkId)

    request.onsuccess = () => {
      logger.debug('IndexedDBManager', `✅ 删除爬取元数据: ${bookmarkId}`)
      resolve()
    }
    request.onerror = () => reject(request.error)
  })
}
```

---

### 阶段3: 修改 lightweight-bookmark-enhancer.ts（15分钟）

#### 3.1 完整替换内容

```typescript
/**
 * 轻量级书签增强器（重构版）
 *
 * 职责：
 * - 提供便捷的爬取 API
 * - 委托给新的本地爬虫服务
 * - 保持向后兼容
 *
 * ⚠️ 已废弃独立 IndexedDB，统一使用 AcuityBookmarksDB
 */

import {
  crawlSingleBookmark,
  crawlMultipleBookmarks,
  getBookmarkMetadata
} from './local-bookmark-crawler'
import { logger } from '@/infrastructure/logging/logger'
import type { CrawlMetadataRecord } from '@/infrastructure/indexeddb/schema'

/**
 * @deprecated 使用 CrawlMetadataRecord 替代
 */
export interface LightweightBookmarkMetadata {
  // 保留类型定义用于向后兼容
  id: string
  url: string
  title: string
  extractedTitle: string
  description: string
  keywords: string
  ogTitle: string
  ogDescription: string
  ogImage: string
  ogSiteName: string
  lastCrawled: number
  crawlSuccess: boolean
  expiresAt: number
  crawlCount: number
  finalUrl: string
  lastModified: string
  crawlStatus: {
    lastCrawled: number
    status: 'success' | 'failed'
    crawlDuration?: number
    version: number
    source: string
    finalUrl?: string
    httpStatus?: number
    error?: string
  }
}

/**
 * 轻量级书签增强器（简化版）
 */
export class LightweightBookmarkEnhancer {
  /**
   * 增强单个书签
   * @deprecated 使用 crawlSingleBookmark 替代
   */
  async enhanceBookmark(
    bookmark: chrome.bookmarks.BookmarkTreeNode
  ): Promise<LightweightBookmarkMetadata> {
    logger.warn(
      'LightweightEnhancer',
      '⚠️ enhanceBookmark 已废弃，请使用 crawlSingleBookmark'
    )

    await crawlSingleBookmark(bookmark)

    // 获取爬取结果
    const metadata = await getBookmarkMetadata(bookmark.id)

    // 转换为旧格式（向后兼容）
    return this.convertToLegacyFormat(bookmark, metadata)
  }

  /**
   * 批量增强书签
   * @deprecated 使用 crawlMultipleBookmarks 替代
   */
  async enhanceBookmarks(
    bookmarks: chrome.bookmarks.BookmarkTreeNode[]
  ): Promise<LightweightBookmarkMetadata[]> {
    logger.warn(
      'LightweightEnhancer',
      '⚠️ enhanceBookmarks 已废弃，请使用 crawlMultipleBookmarks'
    )

    await crawlMultipleBookmarks(bookmarks)

    // 返回空数组（不再返回结果列表）
    return []
  }

  /**
   * 转换为旧格式（向后兼容）
   */
  private convertToLegacyFormat(
    bookmark: chrome.bookmarks.BookmarkTreeNode,
    metadata: CrawlMetadataRecord | null
  ): LightweightBookmarkMetadata {
    if (!metadata) {
      // 返回空元数据
      return {
        id: bookmark.id,
        url: bookmark.url || '',
        title: bookmark.title || '',
        extractedTitle: '',
        description: '',
        keywords: '',
        ogTitle: '',
        ogDescription: '',
        ogImage: '',
        ogSiteName: '',
        lastCrawled: 0,
        crawlSuccess: false,
        expiresAt: 0,
        crawlCount: 0,
        finalUrl: bookmark.url || '',
        lastModified: '',
        crawlStatus: {
          lastCrawled: 0,
          status: 'failed',
          version: 2,
          source: 'local-crawler'
        }
      }
    }

    return {
      id: bookmark.id,
      url: bookmark.url || '',
      title: bookmark.title || '',
      extractedTitle: metadata.pageTitle || '',
      description: metadata.description || '',
      keywords: metadata.keywords || '',
      ogTitle: metadata.ogTitle || '',
      ogDescription: metadata.ogDescription || '',
      ogImage: metadata.ogImage || '',
      ogSiteName: metadata.ogSiteName || '',
      lastCrawled: metadata.lastCrawled || 0,
      crawlSuccess: metadata.crawlSuccess || false,
      expiresAt: metadata.updatedAt + 30 * 24 * 60 * 60 * 1000,
      crawlCount: metadata.crawlCount || 1,
      finalUrl: metadata.finalUrl || bookmark.url || '',
      lastModified: new Date(metadata.updatedAt).toISOString(),
      crawlStatus: {
        lastCrawled: metadata.lastCrawled || 0,
        status: metadata.status || 'failed',
        crawlDuration: metadata.crawlDuration,
        version: 2,
        source: 'local-crawler',
        finalUrl: metadata.finalUrl,
        httpStatus: metadata.httpStatus
      }
    }
  }
}

// 导出单例（向后兼容）
export const lightweightBookmarkEnhancer = new LightweightBookmarkEnhancer()
```

---

### 阶段4: 删除 Serverless Crawler（2分钟）

```bash
# 删除文件
rm frontend/src/services/serverless-crawler-client.ts

# 检查是否有其他引用
grep -r "serverless-crawler-client" frontend/src/
# 如果有输出，需要手动清理这些引用
```

---

### 阶段5: 更新环境变量（1分钟）

在 `.env` 文件中添加或修改：

```bash
# 强制本地模式
VITE_CRAWLER_MODE=local

# 并发控制
VITE_CRAWLER_CONCURRENCY=2
VITE_CRAWLER_PER_DOMAIN_CONCURRENCY=1

# 批量处理
VITE_CRAWLER_BATCH_SIZE=5
VITE_CRAWLER_BATCH_INTERVAL_MS=1500

# 启用空闲调度
VITE_CRAWLER_USE_IDLE_SCHEDULING=true
VITE_CRAWLER_IDLE_DELAY_MS=3000

# 尊重 Robots.txt
VITE_CRAWLER_RESPECT_ROBOTS=true
```

---

### 阶段6: 测试验证（20分钟）

#### 6.1 编译检查

```bash
cd frontend
npm run build
```

如果有类型错误，根据提示修复。

#### 6.2 运行测试

```typescript
// 创建测试文件: frontend/src/services/__tests__/local-crawler.test.ts

import { describe, it, expect } from 'vitest'
import {
  crawlSingleBookmark,
  getBookmarkMetadata,
  saveCrawlResult
} from '../local-bookmark-crawler'
import { crawlBookmarkLocally } from '../local-crawler-worker'

describe('LocalBookmarkCrawler', () => {
  it('should crawl and save bookmark metadata', async () => {
    const testBookmark = {
      id: 'test_123',
      title: 'Test Bookmark',
      url: 'https://example.com',
      dateAdded: Date.now()
    }

    // 爬取
    await crawlSingleBookmark(testBookmark, { force: true })

    // 验证保存
    const metadata = await getBookmarkMetadata('test_123')
    expect(metadata).not.toBeNull()
    expect(metadata?.bookmarkId).toBe('test_123')
    expect(metadata?.url).toBe('https://example.com')
  }, 30000)

  it('should save crawl result correctly', async () => {
    const result = await crawlBookmarkLocally('https://example.com')

    expect(result.success).toBe(true)
    expect(result.metadata).toBeDefined()

    await saveCrawlResult('test_456', 'https://example.com', result)

    const saved = await getBookmarkMetadata('test_456')
    expect(saved).not.toBeNull()
    expect(saved?.pageTitle).toBe(result.metadata?.title)
  }, 30000)
})
```

运行测试：

```bash
npm run test
```

#### 6.3 手动测试

```typescript
// 在浏览器控制台中测试

// 1. 导入
import {
  crawlSingleBookmark,
  getCrawlStatistics
} from './services/local-bookmark-crawler'

// 2. 爬取单个书签
const bookmarks = await chrome.bookmarks.getTree()
const firstBookmark = bookmarks[0].children[0].children[0] // 找到第一个有URL的书签
await crawlSingleBookmark(firstBookmark)

// 3. 检查统计
const stats = await getCrawlStatistics()
console.log('爬取统计:', stats)

// 4. 验证数据保存
const metadata = await getBookmarkMetadata(firstBookmark.id)
console.log('爬取元数据:', metadata)
```

---

### 阶段7: 集成到现有功能（30分钟）

#### 7.1 更新 smart-recommendation-engine.ts

找到所有使用 `lightweightBookmarkEnhancer` 的地方，替换为新 API：

```typescript
// ❌ 旧代码
import { lightweightBookmarkEnhancer } from './lightweight-bookmark-enhancer'
await lightweightBookmarkEnhancer.enhanceBookmark(bookmark)

// ✅ 新代码
import { crawlSingleBookmark } from './local-bookmark-crawler'
await crawlSingleBookmark(bookmark)
```

#### 7.2 更新 Management 页面

添加"刷新元数据"功能：

```vue
<template>
  <button @click="handleRefreshMetadata">🔄 刷新所有书签元数据</button>
</template>

<script setup lang="ts">
import {
  crawlMultipleBookmarks,
  getCrawlStatistics
} from '@/services/local-bookmark-crawler'

async function handleRefreshMetadata() {
  const stats = await getCrawlStatistics()

  const confirmed = confirm(
    `将爬取 ${stats.withoutMetadata} 个未爬取的书签\n` +
      `刷新 ${stats.expired} 个过期的书签\n` +
      `是否继续？`
  )

  if (!confirmed) return

  const bookmarks = await getAllBookmarks()

  await crawlMultipleBookmarks(bookmarks, {
    priority: 'normal',
    skipExisting: true,
    onProgress: progress => {
      console.log(`进度: ${progress.progress}%`)
    },
    onComplete: finalStats => {
      alert(
        `刷新完成！成功: ${finalStats.completed}, 失败: ${finalStats.failed}`
      )
    }
  })
}
</script>
```

#### 7.3 Background Script 初始化

```typescript
// frontend/background.js

import { warmupOffscreenDocument } from './src/services/local-crawler-worker'
import { crawlTaskScheduler } from './src/services/crawl-task-scheduler'

// 扩展启动时
chrome.runtime.onStartup.addListener(async () => {
  console.log('🚀 AcuityBookmarks 已启动')

  // 预热 Offscreen Document
  await warmupOffscreenDocument()

  // 恢复中断的爬取任务
  const stats = crawlTaskScheduler.getStatistics()
  if (stats.pending > 0) {
    console.log(`📂 恢复 ${stats.pending} 个待处理任务`)
    crawlTaskScheduler.resume()
  }
})

// 新增书签时自动爬取
chrome.bookmarks.onCreated.addListener(async (id, bookmark) => {
  if (!bookmark.url || bookmark.url.startsWith('chrome://')) return

  const { crawlSingleBookmark } = await import(
    './src/services/local-bookmark-crawler'
  )
  await crawlSingleBookmark(bookmark)
})
```

---

### 阶段8: 清理和优化（10分钟）

#### 8.1 删除旧数据库（可选）

用户首次运行新版本时，可以提示是否删除旧数据库：

```typescript
async function cleanupOldDatabase() {
  try {
    const oldDBName = 'AcuityBookmarks_LightweightCache'

    // 检查是否存在
    const databases = await indexedDB.databases()
    const hasOldDB = databases.some(db => db.name === oldDBName)

    if (hasOldDB) {
      const confirmed = confirm(
        '检测到旧版本的爬取数据库\n' + '是否删除？（新版本已使用统一数据库）'
      )

      if (confirmed) {
        await indexedDB.deleteDatabase(oldDBName)
        console.log('✅ 已删除旧数据库')
      }
    }
  } catch (error) {
    console.error('清理旧数据库失败:', error)
  }
}

// 在初始化时调用
cleanupOldDatabase()
```

#### 8.2 代码格式化

```bash
npm run lint:fix
npm run format
```

---

## ✅ 完成验证

### 验证清单

- [ ] 编译通过，无类型错误
- [ ] 所有测试通过
- [ ] 手动测试爬取功能正常
- [ ] 数据保存到 `crawlMetadata` 表
- [ ] `bookmarks.hasMetadata` 字段正确更新
- [ ] 搜索能匹配爬取的元数据
- [ ] 无 Serverless Crawler 代码残留
- [ ] 无独立 IndexedDB 残留
- [ ] 100% 本地执行，无数据上传

### 性能验证

测试 100 个书签的爬取：

```typescript
const startTime = Date.now()

await crawlMultipleBookmarks(bookmarks.slice(0, 100), {
  priority: 'high',
  onComplete: stats => {
    const duration = (Date.now() - startTime) / 1000
    console.log(`
      ✅ 爬取完成
      总数: ${stats.total}
      成功: ${stats.completed}
      失败: ${stats.failed}
      耗时: ${duration}秒
      平均: ${(duration / stats.total).toFixed(2)}秒/个
    `)
  }
})
```

预期结果：

- 100个书签 < 3分钟
- 成功率 > 90%
- 内存占用 < 80MB
- CPU占用 < 10%

---

## 🎉 完成！

所有步骤完成后，你的项目将：

✅ **100% 本地执行** - 无数据上传，保护隐私  
✅ **统一数据管理** - 使用 `AcuityBookmarksDB`  
✅ **数据正确关联** - `bookmarks` ↔ `crawlMetadata`  
✅ **代码干净整洁** - 无冗余、无混淆  
✅ **性能体验优秀** - 队列、缓存、分批执行

---

**版本**: v1.0  
**创建时间**: 2025-10-12  
**预计耗时**: 1.5-2小时  
**状态**: ✅ 可执行
