# 本地化爬取 - 清理与集成方案

## 📋 现状分析

### 现有实现的问题

```typescript
// ❌ 问题1: 使用 Serverless Crawler，上传数据到服务器
// frontend/src/services/lightweight-bookmark-enhancer.ts
import { serverlessCrawlerClient } from './serverless-crawler-client'

const result = await serverlessCrawlerClient.crawlBookmark(bookmark)
// 数据流向: 客户端 → 后端 → 目标网站 → 后端 → 客户端

// ❌ 问题2: 独立的 IndexedDB，与主数据库分离
const DB_NAME = 'AcuityBookmarks_LightweightCache' // 独立数据库
const STORE_NAME = 'bookmark_metadata' // 独立表

// ❌ 问题3: 数据未与主书签表关联
// 爬取的数据保存在独立数据库中，没有更新 bookmarks 表的关联字段
```

### 统一的数据库架构

```typescript
// ✅ 正确的架构
// 主数据库: AcuityBookmarksDB (version 7)

// 表1: bookmarks - 书签记录
interface BookmarkRecord {
  id: string
  title: string
  url?: string

  // 元数据关联字段
  hasMetadata?: boolean // 是否有爬取元数据
  metadataUpdatedAt?: number // 元数据更新时间
  metadataSource?: 'chrome' | 'crawler' | 'merged'

  // 派生字段（用于搜索增强）
  metaTitleLower?: string
  metaDescriptionLower?: string
  metaKeywordsTokens?: string[]
  metaBoost?: number
}

// 表2: crawlMetadata - 爬取元数据
interface CrawlMetadataRecord {
  bookmarkId: string // 主键，关联到 bookmarks.id
  url: string
  finalUrl?: string
  domain?: string

  // 爬取的元数据
  pageTitle?: string
  description?: string
  keywords?: string
  ogTitle?: string
  ogDescription?: string
  ogImage?: string
  ogSiteName?: string

  // 状态
  source: 'chrome' | 'crawler' | 'merged'
  status?: 'success' | 'failed' | 'partial'
  httpStatus?: number
  lastCrawled?: number

  // 维护
  updatedAt: number
  version: string
}
```

---

## 🗑️ 清理方案

### 第一步：删除 Serverless Crawler

#### 1.1 删除文件

```bash
# 删除整个 serverless-crawler-client.ts
rm frontend/src/services/serverless-crawler-client.ts
```

#### 1.2 删除相关导入

```typescript
// 在所有文件中删除这行
import { serverlessCrawlerClient } from './serverless-crawler-client'
```

需要检查的文件：

- `frontend/src/services/lightweight-bookmark-enhancer.ts` ✅ **必须修改**
- `frontend/src/services/smart-recommendation-engine.ts` （如果有引用）
- 其他可能的引用

### 第二步：清理独立 IndexedDB

#### 2.1 移除独立数据库代码

```typescript
// ❌ 删除这些代码（lightweight-bookmark-enhancer.ts）

const DB_NAME = 'AcuityBookmarks_LightweightCache'
const DB_VERSION = 1
const STORE_NAME = 'bookmark_metadata'

class LightweightBookmarkEnhancer {
  private db: IDBDatabase | null = null  // ❌ 删除

  private async initDatabase(): Promise<void> {
    // ❌ 整个方法删除
  }

  private async saveToCacheInternal(metadata): Promise<void> {
    // ❌ 整个方法删除
  }

  private async getCachedMetadata(url): Promise<...> {
    // ❌ 整个方法删除
  }
}
```

#### 2.2 使用统一的 IndexedDB Manager

```typescript
// ✅ 使用统一的管理器
import { indexedDBManager } from '@/infrastructure/indexeddb/manager'
import type { CrawlMetadataRecord } from '@/infrastructure/indexeddb/schema'
```

### 第三步：移除混合模式

```typescript
// ❌ 删除混合爬取逻辑

// 不再需要这种模式判断
if (CRAWLER_CONFIG.MODE === 'serverless' || CRAWLER_CONFIG.MODE === 'hybrid') {
  // Serverless 爬取
} else {
  // 本地爬取
}

// ✅ 统一使用本地爬取
const result = await crawlBookmarkLocally(bookmark.url)
```

---

## 🔧 集成方案

### 完整的新架构

```typescript
/**
 * 📁 frontend/src/services/local-bookmark-crawler.ts
 *
 * 新的统一爬虫服务，集成了：
 * - 本地爬取（Offscreen Document）
 * - 任务调度（队列、并发、优先级）
 * - 数据保存（统一 IndexedDB）
 * - 关联更新（bookmarks 表）
 */

import {
  crawlBookmarkLocally,
  type CrawlResult,
  type PageMetadata
} from './local-crawler-worker'
import { crawlTaskScheduler, type CrawlOptions } from './crawl-task-scheduler'
import { indexedDBManager } from '@/infrastructure/indexeddb/manager'
import type {
  CrawlMetadataRecord,
  BookmarkRecord
} from '@/infrastructure/indexeddb/schema'
import { logger } from '@/infrastructure/logging/logger'

// ==================== 保存爬取结果 ====================

/**
 * 保存爬取结果到 IndexedDB
 */
export async function saveCrawlResult(
  bookmarkId: string,
  url: string,
  result: CrawlResult
): Promise<void> {
  try {
    if (!result.success || !result.metadata) {
      // 保存失败记录
      await saveCrawlFailure(bookmarkId, url, result)
      return
    }

    const metadata = result.metadata

    // 1. 构建 CrawlMetadataRecord
    const crawlRecord: CrawlMetadataRecord = {
      // 关联字段
      bookmarkId,
      url,
      finalUrl: result.url,
      domain: extractDomain(result.url),

      // 元数据字段
      pageTitle: metadata.title,
      description: metadata.description,
      keywords: metadata.keywords,
      ogTitle: metadata.ogTitle,
      ogDescription: metadata.ogDescription,
      ogImage: metadata.ogImage,
      ogSiteName: metadata.ogSiteName,
      faviconUrl: metadata.iconHref,

      // 状态字段
      source: 'crawler',
      status: 'success',
      httpStatus: result.httpStatus,
      statusGroup: getStatusGroup(result.httpStatus),
      robotsAllowed: result.robotsAllowed,
      crawlSuccess: true,
      crawlCount: 1,
      lastCrawled: Date.now(),
      crawlDuration: result.duration,

      // 维护字段
      updatedAt: Date.now(),
      version: '2.0'
    }

    // 2. 保存到 crawlMetadata 表
    await indexedDBManager.saveCrawlMetadata(crawlRecord)

    // 3. 更新 bookmarks 表的关联字段
    await updateBookmarkMetadataFields(bookmarkId, metadata)

    logger.info('CrawlSaver', `✅ 保存爬取结果: ${url}`)
  } catch (error) {
    logger.error('CrawlSaver', `❌ 保存失败: ${url}`, error)
    throw error
  }
}

/**
 * 保存失败记录
 */
async function saveCrawlFailure(
  bookmarkId: string,
  url: string,
  result: CrawlResult
): Promise<void> {
  const crawlRecord: CrawlMetadataRecord = {
    bookmarkId,
    url,
    domain: extractDomain(url),

    // 失败状态
    source: 'crawler',
    status: 'failed',
    httpStatus: result.httpStatus || 0,
    statusGroup: result.httpStatus
      ? getStatusGroup(result.httpStatus)
      : 'error',
    robotsAllowed: result.robotsAllowed,
    crawlSuccess: false,
    crawlCount: 1,
    lastCrawled: Date.now(),
    crawlDuration: result.duration,

    // 维护字段
    updatedAt: Date.now(),
    version: '2.0'
  }

  await indexedDBManager.saveCrawlMetadata(crawlRecord)
}

/**
 * 更新 bookmarks 表的元数据关联字段
 */
async function updateBookmarkMetadataFields(
  bookmarkId: string,
  metadata: PageMetadata
): Promise<void> {
  const bookmark = await indexedDBManager.getBookmarkById(bookmarkId)
  if (!bookmark) {
    logger.warn('CrawlSaver', `书签不存在: ${bookmarkId}`)
    return
  }

  // 更新派生字段（用于搜索增强）
  const updates: Partial<BookmarkRecord> = {
    // 关联字段
    hasMetadata: true,
    metadataUpdatedAt: Date.now(),
    metadataSource: 'crawler',

    // 派生字段（小写，用于搜索）
    metaTitleLower: (metadata.title || '').toLowerCase(),
    metaDescriptionLower: (metadata.description || '').toLowerCase(),
    metaKeywordsTokens: metadata.keywords
      ? metadata.keywords
          .toLowerCase()
          .split(/[,\s]+/)
          .filter(Boolean)
      : [],

    // 搜索权重提升
    metaBoost: calculateMetadataBoost(metadata)
  }

  await indexedDBManager.updateBookmark(bookmarkId, updates)
}

/**
 * 计算元数据搜索权重
 */
function calculateMetadataBoost(metadata: PageMetadata): number {
  let boost = 1.0

  // 有标题 +0.2
  if (metadata.title) boost += 0.2

  // 有描述 +0.2
  if (metadata.description) boost += 0.2

  // 有关键词 +0.1
  if (metadata.keywords) boost += 0.1

  // 有 OG 数据 +0.1
  if (metadata.ogTitle || metadata.ogDescription) boost += 0.1

  return boost
}

/**
 * 提取域名
 */
function extractDomain(url: string): string {
  try {
    return new URL(url).hostname
  } catch {
    return ''
  }
}

/**
 * 获取 HTTP 状态分组
 */
function getStatusGroup(status?: number): CrawlMetadataRecord['statusGroup'] {
  if (!status) return 'error'
  if (status >= 200 && status < 300) return '2xx'
  if (status >= 300 && status < 400) return '3xx'
  if (status >= 400 && status < 500) return '4xx'
  if (status >= 500) return '5xx'
  return 'error'
}

// ==================== 高级 API ====================

/**
 * 爬取单个书签
 */
export async function crawlSingleBookmark(
  bookmark: chrome.bookmarks.BookmarkTreeNode
): Promise<void> {
  if (!bookmark.url) return

  const result = await crawlBookmarkLocally(bookmark.url, {
    respectRobots: true,
    timeout: 10000
  })

  await saveCrawlResult(bookmark.id, bookmark.url, result)
}

/**
 * 批量爬取书签（使用任务调度器）
 */
export async function crawlMultipleBookmarks(
  bookmarks: chrome.bookmarks.BookmarkTreeNode[],
  options?: CrawlOptions
): Promise<void> {
  await crawlTaskScheduler.scheduleBookmarksCrawl(bookmarks, {
    ...options,
    onTaskComplete: async task => {
      if (task.result) {
        await saveCrawlResult(task.bookmarkId, task.url, task.result)
      }
    }
  })
}

/**
 * 获取书签的爬取元数据
 */
export async function getBookmarkMetadata(
  bookmarkId: string
): Promise<CrawlMetadataRecord | null> {
  return await indexedDBManager.getCrawlMetadata(bookmarkId)
}

/**
 * 检查书签是否需要爬取
 */
export async function needsCrawl(bookmarkId: string): Promise<boolean> {
  const metadata = await indexedDBManager.getCrawlMetadata(bookmarkId)

  // 没有元数据，需要爬取
  if (!metadata) return true

  // 爬取失败，需要重试
  if (!metadata.crawlSuccess) {
    const daysSinceLastCrawl =
      (Date.now() - (metadata.lastCrawled || 0)) / (1000 * 60 * 60 * 24)
    return daysSinceLastCrawl > 1 // 失败1天后重试
  }

  // 成功但过期（30天），需要刷新
  const daysSinceUpdate =
    (Date.now() - metadata.updatedAt) / (1000 * 60 * 60 * 24)
  return daysSinceUpdate > 30
}

/**
 * 获取需要爬取的书签列表
 */
export async function getBookmarksNeedingCrawl(): Promise<
  chrome.bookmarks.BookmarkTreeNode[]
> {
  const allBookmarks = await chrome.bookmarks.getTree()
  const flatBookmarks = flattenBookmarkTree(allBookmarks)

  const needsCrawlList: chrome.bookmarks.BookmarkTreeNode[] = []

  for (const bookmark of flatBookmarks) {
    if (!bookmark.url || bookmark.url.startsWith('chrome://')) continue

    const needs = await needsCrawl(bookmark.id)
    if (needs) {
      needsCrawlList.push(bookmark)
    }
  }

  return needsCrawlList
}

/**
 * 扁平化书签树
 */
function flattenBookmarkTree(
  nodes: chrome.bookmarks.BookmarkTreeNode[]
): chrome.bookmarks.BookmarkTreeNode[] {
  const result: chrome.bookmarks.BookmarkTreeNode[] = []

  function traverse(node: chrome.bookmarks.BookmarkTreeNode) {
    if (node.url) {
      result.push(node)
    }

    if (node.children) {
      node.children.forEach(traverse)
    }
  }

  nodes.forEach(traverse)
  return result
}
```

---

## 🔄 修改现有文件

### 修改1: `lightweight-bookmark-enhancer.ts`

**完整重构版本**（只保留必要功能）：

```typescript
/**
 * 轻量级书签增强器（重构版）
 *
 * 职责：
 * - 提供便捷的爬取 API
 * - 委托给新的本地爬虫服务
 * - 保持向后兼容
 *
 * ⚠️ 已废弃独立 IndexedDB，统一使用 AcuityBookmarksDB
 */

import {
  crawlSingleBookmark,
  crawlMultipleBookmarks
} from './local-bookmark-crawler'
import { logger } from '@/infrastructure/logging/logger'

/**
 * @deprecated 使用 CrawlMetadataRecord 替代
 */
export interface LightweightBookmarkMetadata {
  // 保留类型定义用于向后兼容
  id: string
  url: string
  title: string
  extractedTitle: string
  description: string
  keywords: string
  ogTitle: string
  ogDescription: string
  ogImage: string
  ogSiteName: string
  // ... 其他字段
}

/**
 * 轻量级书签增强器（简化版）
 */
export class LightweightBookmarkEnhancer {
  /**
   * 增强单个书签
   * @deprecated 使用 crawlSingleBookmark 替代
   */
  async enhanceBookmark(
    bookmark: chrome.bookmarks.BookmarkTreeNode
  ): Promise<void> {
    logger.warn(
      'LightweightEnhancer',
      '⚠️ enhanceBookmark 已废弃，使用 crawlSingleBookmark'
    )
    await crawlSingleBookmark(bookmark)
  }

  /**
   * 批量增强书签
   * @deprecated 使用 crawlMultipleBookmarks 替代
   */
  async enhanceBookmarks(
    bookmarks: chrome.bookmarks.BookmarkTreeNode[]
  ): Promise<void> {
    logger.warn(
      'LightweightEnhancer',
      '⚠️ enhanceBookmarks 已废弃，使用 crawlMultipleBookmarks'
    )
    await crawlMultipleBookmarks(bookmarks)
  }
}

// 导出单例（向后兼容）
export const lightweightBookmarkEnhancer = new LightweightBookmarkEnhancer()
```

### 修改2: 添加 IndexedDB Manager 方法

在 `utils-legacy/indexeddb-manager.ts` 中添加：

```typescript
/**
 * 保存爬取元数据
 */
async saveCrawlMetadata(record: CrawlMetadataRecord): Promise<void> {
  if (!this.db) {
    throw new Error('Database not initialized')
  }

  return new Promise((resolve, reject) => {
    const transaction = this.db!.transaction([DB_CONFIG.STORES.CRAWL_METADATA], 'readwrite')
    const store = transaction.objectStore(DB_CONFIG.STORES.CRAWL_METADATA)
    const request = store.put(record)

    request.onsuccess = () => resolve()
    request.onerror = () => reject(request.error)
  })
}

/**
 * 获取爬取元数据
 */
async getCrawlMetadata(bookmarkId: string): Promise<CrawlMetadataRecord | null> {
  if (!this.db) {
    throw new Error('Database not initialized')
  }

  return new Promise((resolve, reject) => {
    const transaction = this.db!.transaction([DB_CONFIG.STORES.CRAWL_METADATA], 'readonly')
    const store = transaction.objectStore(DB_CONFIG.STORES.CRAWL_METADATA)
    const request = store.get(bookmarkId)

    request.onsuccess = () => resolve(request.result || null)
    request.onerror = () => reject(request.error)
  })
}

/**
 * 批量获取爬取元数据
 */
async getBatchCrawlMetadata(bookmarkIds: string[]): Promise<Map<string, CrawlMetadataRecord>> {
  const result = new Map<string, CrawlMetadataRecord>()

  for (const id of bookmarkIds) {
    const metadata = await this.getCrawlMetadata(id)
    if (metadata) {
      result.set(id, metadata)
    }
  }

  return result
}

/**
 * 删除爬取元数据
 */
async deleteCrawlMetadata(bookmarkId: string): Promise<void> {
  if (!this.db) {
    throw new Error('Database not initialized')
  }

  return new Promise((resolve, reject) => {
    const transaction = this.db!.transaction([DB_CONFIG.STORES.CRAWL_METADATA], 'readwrite')
    const store = transaction.objectStore(DB_CONFIG.STORES.CRAWL_METADATA)
    const request = store.delete(bookmarkId)

    request.onsuccess = () => resolve()
    request.onerror = () => reject(request.error)
  })
}
```

---

## 📋 清理检查清单

### 必须删除的文件

- [ ] `frontend/src/services/serverless-crawler-client.ts`

### 必须修改的文件

- [ ] `frontend/src/services/lightweight-bookmark-enhancer.ts`
  - [ ] 删除 `serverlessCrawlerClient` 导入
  - [ ] 删除独立 IndexedDB 代码
  - [ ] 使用新的 `local-bookmark-crawler`

- [ ] `frontend/src/services/crawl-task-scheduler.ts`
  - [ ] 集成数据保存逻辑

- [ ] `frontend/src/utils-legacy/indexeddb-manager.ts`
  - [ ] 添加 `saveCrawlMetadata` 方法
  - [ ] 添加 `getCrawlMetadata` 方法

### 需要创建的文件

- [ ] `frontend/src/services/local-bookmark-crawler.ts`（新文件，统一入口）

### 需要检查的文件

- [ ] `frontend/src/services/smart-recommendation-engine.ts`
  - [ ] 检查是否引用了 `serverlessCrawlerClient`
  - [ ] 检查是否引用了旧的 `lightweightBookmarkEnhancer`

- [ ] `frontend/background.js`
  - [ ] 更新导入路径

### 环境变量

- [ ] `.env` 文件
  ```bash
  # 强制本地模式
  VITE_CRAWLER_MODE=local
  ```

---

## 🧪 测试验证

### 测试1: 数据保存验证

```typescript
// 测试保存到正确的表
async function testDataSaving() {
  const testBookmark = {
    id: 'test_123',
    title: 'Test',
    url: 'https://example.com'
  }

  // 1. 爬取
  await crawlSingleBookmark(testBookmark)

  // 2. 验证 crawlMetadata 表
  const crawlData = await indexedDBManager.getCrawlMetadata('test_123')
  console.assert(crawlData !== null, 'crawlMetadata 应该存在')
  console.assert(crawlData.bookmarkId === 'test_123', 'bookmarkId 应该匹配')

  // 3. 验证 bookmarks 表
  const bookmark = await indexedDBManager.getBookmarkById('test_123')
  console.assert(bookmark.hasMetadata === true, 'hasMetadata 应该为 true')
  console.assert(bookmark.metadataUpdatedAt > 0, 'metadataUpdatedAt 应该被设置')

  console.log('✅ 数据保存验证通过')
}
```

### 测试2: 关联查询验证

```typescript
// 测试书签与元数据的关联
async function testDataAssociation() {
  const bookmark = await indexedDBManager.getBookmarkById('test_123')

  if (bookmark.hasMetadata) {
    const metadata = await indexedDBManager.getCrawlMetadata(bookmark.id)
    console.assert(metadata !== null, '关联的元数据应该存在')
    console.log('✅ 关联查询验证通过')
  }
}
```

### 测试3: 搜索增强验证

```typescript
// 测试元数据是否增强了搜索
async function testSearchEnhancement() {
  // 搜索时应该能匹配元数据中的内容
  const results = await searchBookmarks('关键词来自元数据')

  console.assert(results.length > 0, '应该能搜索到元数据中的内容')
  console.log('✅ 搜索增强验证通过')
}
```

---

## 📊 数据迁移

### 迁移旧数据（可选）

如果需要迁移 `AcuityBookmarks_LightweightCache` 中的数据：

```typescript
async function migrateOldCrawlData() {
  // 1. 打开旧数据库
  const oldDB = await new Promise<IDBDatabase>((resolve, reject) => {
    const request = indexedDB.open('AcuityBookmarks_LightweightCache', 1)
    request.onsuccess = () => resolve(request.result)
    request.onerror = () => reject(request.error)
  })

  // 2. 读取所有数据
  const oldData: any[] = await new Promise((resolve, reject) => {
    const transaction = oldDB.transaction(['bookmark_metadata'], 'readonly')
    const store = transaction.objectStore('bookmark_metadata')
    const request = store.getAll()

    request.onsuccess = () => resolve(request.result)
    request.onerror = () => reject(request.error)
  })

  // 3. 转换并保存到新数据库
  for (const old of oldData) {
    const newRecord: CrawlMetadataRecord = {
      bookmarkId: old.id,
      url: old.url,
      pageTitle: old.extractedTitle,
      description: old.description,
      keywords: old.keywords,
      ogTitle: old.ogTitle,
      ogDescription: old.ogDescription,
      ogImage: old.ogImage,
      ogSiteName: old.ogSiteName,
      source: 'crawler',
      status: old.crawlSuccess ? 'success' : 'failed',
      lastCrawled: old.lastCrawled,
      updatedAt: old.lastCrawled || Date.now(),
      version: '2.0'
    }

    await indexedDBManager.saveCrawlMetadata(newRecord)
  }

  // 4. 删除旧数据库
  oldDB.close()
  await indexedDB.deleteDatabase('AcuityBookmarks_LightweightCache')

  console.log(`✅ 迁移完成: ${oldData.length} 条记录`)
}
```

---

## 🎯 实施步骤

### 第1天：清理代码

1. ✅ 删除 `serverless-crawler-client.ts`
2. ✅ 创建 `local-bookmark-crawler.ts`
3. ✅ 修改 `lightweight-bookmark-enhancer.ts`
4. ✅ 更新 IndexedDB Manager

### 第2天：测试验证

1. ✅ 单元测试
2. ✅ 集成测试
3. ✅ 数据保存验证
4. ✅ 关联查询验证

### 第3天：数据迁移

1. ✅ 迁移脚本（如需要）
2. ✅ 清理旧数据库
3. ✅ 性能测试

---

## ✅ 完成标志

- [ ] 所有 `serverless-crawler-client` 引用已清理
- [ ] 数据保存到 `crawlMetadata` 表
- [ ] `bookmarks` 表的 `hasMetadata` 字段正确更新
- [ ] 搜索能匹配元数据内容
- [ ] 没有独立的 `AcuityBookmarks_LightweightCache` 数据库
- [ ] 所有测试通过
- [ ] 100% 本地执行，无数据上传

---

**版本**: v1.0  
**创建时间**: 2025-10-12  
**状态**: ✅ 待实施
